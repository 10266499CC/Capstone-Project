{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dbs.ie/images/default-source/logos/dbs-logo-2019-small.png\" align = left/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Open University Learning Analytics Dataset Preparation\n",
    "\n",
    "Capstone Project\n",
    "\n",
    "Claire Connaughton (10266499)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Relevant Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "plotnine.options.figure_size = (5.2,3.2)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OULA dataset contains 7 separate csv files. The database schema is displayed below. \n",
    "Source: https://analyse.kmi.open.ac.uk/open_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](schema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each csv file will be loaded and inspected once by one to get an insight into the tables.\n",
    "Each csv file will be cleaned sequentially before finally being merged into the final dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Courses "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains information about contains the list of all available modules and their presentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load courses table\n",
    "\n",
    "try:\n",
    "    courses = pd.read_csv('courses.csv')\n",
    "    print(\"The 'courses' table has {} samples with {} features each.\".format(*courses.shape))\n",
    "    display(courses.info())\n",
    "    display(courses.head())\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Feature Description for Courses\n",
    "\n",
    "code_module – code name of the module, which serves as the identifier.\n",
    "\n",
    "code_presentation – code name of the presentation. It consists of the year and “B” for the presentation starting in February and “J” for the presentation starting in October.\n",
    "\n",
    "length - length of the module-presentation in days.\n",
    "\n",
    "The structure of B and J presentations may differ and therefore it is good practice to analyse the B and J presentations separately. Nevertheless, for some presentations the corresponding previous B/J presentation do not exist and therefore the J presentation must be used to inform the B presentation or vice versa. In the dataset this is the case of CCC, EEE and GGG modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting the most common course length\n",
    "g = sns.countplot(x ='module_presentation_length', \n",
    "              data = courses,\n",
    "              color='grey',\n",
    "              order = courses.module_presentation_length.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Module Duration (in days)', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most courses last around 8 months each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visulaise the breakdown in module length per module type\n",
    "\n",
    "g= sns.catplot('module_presentation_length', col='code_module', col_wrap=4,\n",
    "                data=courses[courses.code_module.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Length of Modules', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the modules are different lengths for every intake. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(courses.module_presentation_length, courses.code_presentation).plot.barh(stacked = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot further verifies that the course presentation lenght varies with every year, albeit slightly. This indicates that the course presentation length offers little value to the analysis because it varies with every year and module. Therefore it may need to be discarded. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assessments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains information about assessments in module-presentations.\n",
    "Usually, every presentation has a number of assessments followed by the final exam. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load assessments table\n",
    "\n",
    "try:\n",
    "    assessments = pd.read_csv('assessments.csv')\n",
    "    print(\"The 'assessments' table has {} samples with {} features each.\".format(*assessments.shape))\n",
    "    display(assessments.info())\n",
    "    display(assessments.head())\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Feature Description for Assessments:\n",
    "\n",
    "code_module – identification code of the module, to which the assessment belongs.\n",
    "\n",
    "code_presentation - identification code of the presentation, to which the assessment belongs.\n",
    "\n",
    "id_assessment – identification number of the assessment.\n",
    "\n",
    "assessment_type – type of assessment. Three types of assessments exist: Tutor Marked Assessment (TMA), Computer Marked Assessment (CMA) and Final Exam (Exam).\n",
    "\n",
    "date – information about the final submission date of the assessment calculated as the number of days since the start of the module-presentation. The starting date of the presentation has number 0 (zero).\n",
    "\n",
    "weight - weight of the assessment in %. Typically, Exams are treated separately and have the weight 100%; the sum of all other assessments is 100%.\n",
    "\n",
    "If the information about the final exam date is missing, it is at the end of the last presentation week."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*****************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Cleaning for Assessments is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Assessments IDs from integers to categorical datatypes\n",
    "\n",
    "assessments['id_assessment'] = assessments['id_assessment'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(assessments.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check weightings of assessment results.\n",
    "# The weighting of exams is 100%\n",
    "# The weighting of the sum of assessments is 100%\n",
    "# Modules with assessments and exams would have a weighting of 200%\n",
    "\n",
    "# Determine the weightings of each module\n",
    "\n",
    "assessments\\\n",
    ".groupby(['code_module','code_presentation', 'assessment_type'])\\\n",
    ".agg(weight_by_type = ('weight', sum))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This indicates that the modules have both assessments (100%) and exam (100%) which is why their weighting is 200.\n",
    "\n",
    "The exeptions are:\n",
    "    \n",
    "    Module CCC which has a score of 200 for exams. This suggests 2 exams.\n",
    "    Module GGG which has a score of 0 for assignments. This suggests no assignments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there are 2 exams in Module CCC\n",
    "assessments[(assessments['code_module'] == 'CCC') & (assessments['assessment_type'] == 'Exam')][['code_module', 'code_presentation', 'assessment_type']]\\\n",
    ".groupby(['code_module', 'code_presentation'])\\\n",
    ".count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that there are two exams in Module CCC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that there is only 1 exam in Module GGG\n",
    "assessments[(assessments['code_module'] == 'GGG') & (assessments['assessment_type'] == 'Exam')][['code_module', 'code_presentation', 'assessment_type']]\\\n",
    ".groupby(['code_module', 'code_presentation'])\\\n",
    ".count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that there is only one exam in Module GGG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Highlighting the assessment types\n",
    "sns.set_style(\"white\")\n",
    "g = sns.countplot(x ='assessment_type', \n",
    "              data = assessments,\n",
    "              color='grey',\n",
    "              order = assessments.assessment_type.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Types of Assessments', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TMAs are the most common assessment types. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the assessment breakdown per module\n",
    "\n",
    "sns.set(style='white')\n",
    "\n",
    "# Plot\n",
    "g = sns.catplot(\"code_module\", col=\"assessment_type\",\n",
    "                data=assessments[assessments.assessment_type.notnull()],\n",
    "                kind=\"count\", height=4, aspect=1.0, palette='tab20')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every module has an exam and TMAs. AAA and EEE have no CMA assessments. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student Results (studentAssssments table)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains the results of students’ assessments. \n",
    "If the student does not submit the assessment, no result is recorded. \n",
    "The final exam submissions is missing, if the result of the assessments is not stored in the system.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Results table\n",
    "\n",
    "try:\n",
    "    results = pd.read_csv('studentAssessment.csv')\n",
    "    print(\"The 'Results' table has {} samples with {} features each.\".format(*results.shape))\n",
    "    display(results.info())\n",
    "    display(results.head())\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                    Feature Description\n",
    "\n",
    "id_assessment – the identification number of the assessment.\n",
    "\n",
    "id_student – a unique identification number for the student.\n",
    "\n",
    "date_submitted – the date of student submission, measured as the number of days since the start of the module presentation.\n",
    "\n",
    "is_banked – a status flag indicating that the assessment result has been transferred from a previous presentation.\n",
    "\n",
    "score – the student’s score in this assessment. The range is from 0 to 100. The score lower than 40 is interpreted as Fail. The marks are in the range from 0 to 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data types of id_assessment and id_student from integer to categorical\n",
    "\n",
    "results['id_assessment'] = results['id_assessment'].astype(object)\n",
    "results['id_student'] = results['id_student'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print((results.info()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check whether the Assessments information is in the Results Table\n",
    "\n",
    "def compareCols(df1, df2):\n",
    "\n",
    "    # Show shared columns between dataframes\n",
    "    # (a) Make lists of columns for each data frame\n",
    "    df1Columns = df1.columns.values.tolist()\n",
    "    df2Columns = df2.columns.values.tolist()\n",
    "\n",
    "    # (b) Find column names that are the same\n",
    "    diffDict = set(df1Columns) & set(df2Columns)\n",
    "    \n",
    "    print('Shared columns : ', diffDict, '\\n')\n",
    "\n",
    "    # (c) Make a list of the dictinary\n",
    "    diffList = list(diffDict)\n",
    "    # (d) Check that if values in\n",
    "    # every shared column match in\n",
    "    # the two dataframes\n",
    "    for col in diffList:\n",
    "        x = df1[col].isin(df2[col]).value_counts()\n",
    "        print('Check if values are present in both dataframes:')\n",
    "        print(x, '\\n')\n",
    "\n",
    "compareCols(assessments, results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine what assignments are missing from the results table \n",
    "\n",
    "def printDiffValues(df1, df2, col):\n",
    "    '''\n",
    "    Show all df1.col values not present in df2.col\n",
    "    '''\n",
    "    # Pull out all unique values id_assessments\n",
    "    df1_IDs = df1[col].unique()\n",
    "    df2_IDs = df2[col].unique()\n",
    "\n",
    "    # Compare the two lists\n",
    "    # (a) Find what values are different\n",
    "    diff = set(df1_IDs).difference(set(df2_IDs))\n",
    "    \n",
    "    # Show information for all df1.col values not presentin df2.col\n",
    "    # (a) Make a list of missing values\n",
    "    missingList = list(diff)\n",
    "    # (b) Find these IDs in df2\n",
    "    missingDf = df1[df1[col].isin(missingList)]\n",
    "\n",
    "    return missingDf\n",
    "\n",
    "printDiffValues(assessments, results, 'id_assessment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All assignments missing from the Results table are exams with 100% module weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Materials (VLE table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The csv file contains information about the available materials in the VLE. \n",
    "Typically these are html pages, pdf files, etc. \n",
    "Students have access to these materials online and their interactions with the materials are recorded. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vle table\n",
    "\n",
    "try:\n",
    "    materials = pd.read_csv('vle.csv')\n",
    "    print(\"The 'Materials' table has {} samples with {} features each.\".format(*materials.shape))\n",
    "    display(materials.info())\n",
    "    display(materials.head())\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "            Feature Description:\n",
    "    \n",
    "id_site – an identification number of the material.\n",
    "\n",
    "code_module – an identification code for module.\n",
    "\n",
    "code_presentation - the identification code of presentation.\n",
    "\n",
    "activity_type – the role associated with the module material.\n",
    "\n",
    "week_from – the week from which the material is planned to be used.\n",
    "\n",
    "week_to – week until which the material is planned to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change id_site from integer to categorical \n",
    "materials['id_site'] = materials['id_site'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart the most common VLE activities\n",
    "sns.set_style(\"white\")\n",
    "g = sns.countplot(y= \"activity_type\", \n",
    "              data = materials,\n",
    "              color='grey',\n",
    "              order = materials.activity_type.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Most Common VLE Activities', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resource, oucontent, subpage and url are the most popular activities on the VLE. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "******************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StudentInfo Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains demographic information about the students together with their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load studentInfo table\n",
    "\n",
    "try:\n",
    "    studentInfo = pd.read_csv('studentInfo.csv')\n",
    "    print(\"The 'studentInfo' table has {} samples with {} features each.\".format(*studentInfo.shape))\n",
    "    display(studentInfo.info())\n",
    "    display(studentInfo.head())\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                        Feature Description\n",
    "\n",
    "code_module – an identification code for a module on which the student is registered.\n",
    "\n",
    "code_presentation - the identification code of the presentation during which the student is registered on the module.\n",
    "\n",
    "id_student – a unique identification number for the student.\n",
    "\n",
    "gender – the student’s gender.\n",
    "\n",
    "region – identifies the geographic region, where the student lived while taking the module-presentation.\n",
    "\n",
    "highest_education – highest student education level on entry to the module presentation.\n",
    "\n",
    "imd_band – specifies the Index of Multiple Depravation band of the place where the student lived during the module-presentation.\n",
    "\n",
    "age_band – band of the student’s age.\n",
    "\n",
    "num_of_prev_attempts – the number times the student has attempted this module.\n",
    "\n",
    "studied_credits – the total number of credits for the modules the student is currently studying.\n",
    "\n",
    "disability – indicates whether the student has declared a disability.\n",
    "\n",
    "final_result – student’s final result in the module-presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the data type for id_student from integer to categorical\n",
    "\n",
    "studentInfo['id_student'] = studentInfo['id_student'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect boxplots of the numeric variables\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "studentInfo.boxplot(column=['num_of_prev_attempts'], grid=False,  ax=ax[0], patch_artist=True)\n",
    "studentInfo.boxplot(column=['studied_credits'],  grid=False,  ax=ax[1], patch_artist=True)\n",
    "print(\"Boxplots for numerical variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is evidence of outliers in the studied_credits column. This will need to be cleaned later. It is also clear that the num_of_prev_attempts is an ordinal variable, not a continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the num_of_prev_attempts to a categorical variable because it could not be visualised using a box plot\n",
    "\n",
    "studentInfo.num_of_prev_attempts=pd.Categorical(studentInfo.num_of_prev_attempts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the counts of each category\n",
    "\n",
    "studentInfo.num_of_prev_attempts.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The majority of students completed the module on their first attempt. The categories should be collapsed further during cleaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the categorical variables\n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "# Code Module\n",
    "g_1 = sns.countplot(x ='code_module', \n",
    "              data = studentInfo,\n",
    "              ax=ax[0],\n",
    "              color='grey',\n",
    "              order = studentInfo.code_module.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_1.set_title('Module Codes', fontsize = 18)\n",
    "\n",
    "# Code Presentation\n",
    "g_2= sns.countplot(x ='code_presentation', \n",
    "              data = studentInfo,\n",
    "              ax=ax[1],\n",
    "              color='grey',\n",
    "              order = studentInfo.code_presentation.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_2.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_2.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_2.set_title('Year of Course', fontsize = 18)\n",
    "\n",
    "# Gender\n",
    "g_3= sns.countplot(x ='gender', \n",
    "              data = studentInfo,\n",
    "              ax=ax[2],\n",
    "              color='grey',\n",
    "              order = studentInfo.gender.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_3.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_3.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_3.set_title('Gender', fontsize = 18)\n",
    "\n",
    "print(\"Count plots for code_module, code_presentation, gender\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 7 module codes. These categories should be condensed futher during cleaning. The code_presentation could be condensed into two year groups. More males were registered than females."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the categorical variables\n",
    "sns.set_style(\"white\")\n",
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "# num_of_prev_attempts\n",
    "g_1 = sns.countplot(x ='num_of_prev_attempts', \n",
    "              data = studentInfo,\n",
    "              ax=ax[0],\n",
    "              color='grey',\n",
    "              order = studentInfo.num_of_prev_attempts.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_1.set_title('Number of Previous Attempts', fontsize = 18)\n",
    "\n",
    "# Disability\n",
    "g_2= sns.countplot(x ='disability', \n",
    "              data = studentInfo,\n",
    "              ax=ax[1],\n",
    "              color='grey',\n",
    "              order = studentInfo.disability.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_2.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_2.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_2.set_title('Disability', fontsize = 18)\n",
    "\n",
    "# Age_band\n",
    "g_3= sns.countplot(x ='age_band', \n",
    "              data = studentInfo,\n",
    "              ax=ax[2],\n",
    "              color='grey',\n",
    "              order = studentInfo.age_band.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_3.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_3.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_3.set_title('Age Band', fontsize = 18)\n",
    "\n",
    "print(\"Count plots for num_of_previous_attempts, disability, final_result, age_band\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vast majority of students completed the course on their first attempt. Very few had a disability. Most were aged 35 and under. Most students passed the course but the withdrawals are very high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Visualise the most common region\n",
    "g = sns.countplot(y= \"region\", \n",
    "              data = studentInfo,\n",
    "              color='grey',\n",
    "              order = studentInfo.region.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Most Common Region', fontsize = 18)\n",
    "print(\"Count plot for region\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scotland had the most students but overall England had the most students and Ireland had the least. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the most common education band\n",
    "g = sns.countplot(y= \"highest_education\", \n",
    "              data = studentInfo,\n",
    "              color='grey',\n",
    "              order = studentInfo.highest_education.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Most Common Education Level', fontsize = 18)\n",
    "print(\"Count plots for highest_education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the most common imd band\n",
    "g = sns.countplot(y= \"imd_band\", \n",
    "              data = studentInfo,\n",
    "              color='grey',\n",
    "              order = studentInfo.imd_band.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Socio-Economic Status', fontsize = 18)\n",
    "print(\"Count plots for imd_band\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More students from lower income groups were registered. There seems to be a few redundant categories in the highest_education column. This will have to be addressed during cleaning. Not much variation in the imb bands but there are too many bands so this should be condensed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the target variable\n",
    "\n",
    "g = sns.countplot(x ='final_result', \n",
    "              data = studentInfo,\n",
    "              color='grey',\n",
    "              order = studentInfo.final_result.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Student Outcome', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most students passed but the withdrawal and fail rates are high."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the overall fail or withdrawal rate\n",
    "\n",
    "len(studentInfo[(studentInfo['final_result'] == 'Withdrawn') | (studentInfo['final_result'] == 'Fail') ]) / len(studentInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 53% of students either withdrew or failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the overall fail rate\n",
    "\n",
    "len(studentInfo[(studentInfo['final_result'] == 'Fail') ]) / len(studentInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost 23% of the students failed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the overall withdrawal rate\n",
    "\n",
    "len(studentInfo[(studentInfo['final_result'] == 'Withdrawn') ]) / len(studentInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "31% of the students dropped out of their course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StudentRegistration table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file contains information about the time when the student registered for the module presentation. \n",
    "For students who unregistered the date of unregistration is also recorded.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load studentRegistration table\n",
    "try:\n",
    "    studentRegistration = pd.read_csv('studentRegistration.csv')\n",
    "    print(\"The 'studentRegistration' table has {} samples with {} features each.\".format(*studentRegistration.shape))\n",
    "    display(studentRegistration.info())\n",
    "    display(studentRegistration.head())\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Feature Description\n",
    "\n",
    "code_module – an identification code for a module.\n",
    "\n",
    "code_presentation - the identification code of the presentation.\n",
    "\n",
    "id_student – a unique identification number for the student.\n",
    "\n",
    "date_registration – the date of student’s registration on the module presentation, this is the number of days measured relative to the start of the module-presentation (e.g. the negative value -30 means that the student registered to module presentation 30 days before it started).\n",
    "\n",
    "date_unregistration – date of student unregistration from the module presentation, this is the number of days measured relative to the start of the module-presentation. Students, who completed the course have this field empty. Students who unregistered have Withdrawal as the value of the final_result column in the studentInfo.csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the id_student from integer to categorical\n",
    "\n",
    "studentRegistration['id_student'] = studentRegistration['id_student'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all student IDs recorded in the Registration tables are recorded in the Results table\n",
    "\n",
    "compareCols(studentRegistration, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 5847 students missing from the Results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there any students from the Student Information table missing from the Results table\n",
    "\n",
    "compareCols(studentInfo, results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There 5847 students recorded in the Students Information table missing from the Assessment Results table. Are they the same students?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull out all unique values id_assessments\n",
    "df1_IDs = studentRegistration['id_student'].unique()\n",
    "df2_IDs = studentInfo['id_student'].unique()\n",
    "\n",
    "# Compare the two lists\n",
    "# (a) Find what assessment IDs are different\n",
    "diff = set(df1_IDs).difference(set(df2_IDs))\n",
    "# (b) Count how many are different\n",
    "numberDiff = len(diff)\n",
    "\n",
    "numberDiff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This confirms that they are the same students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see their outcome\n",
    "\n",
    "info_not_in_results = printDiffValues(studentInfo, results, 'id_student')\n",
    "\n",
    "column = info_not_in_results['final_result']\n",
    "\n",
    "unique, counts = np.unique(column, return_counts = True)\n",
    "\n",
    "dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strangely, 2 students with no submissions recorded have passed their modules. Further investigation is required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate whether there is a clerical error.\n",
    "# If unregistration dates for these students are found, it is a clerical error.\n",
    "\n",
    "info_not_in_results[info_not_in_results['final_result'] == 'Pass']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unregistered date for id_student 1336190\n",
    "\n",
    "reg_not_in_results = printDiffValues(studentRegistration, results, 'id_student')\n",
    "reg_not_in_results[reg_not_in_results['id_student'] == 1336190]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find unregistered date for id_student 1777834\n",
    "\n",
    "reg_not_in_results[reg_not_in_results['id_student'] == 1777834]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no unregistration dates for these 2 students indicating that it is not a clerical error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the dates into month and week number for easier visualisation\n",
    "\n",
    "# Sep Oct Nov Dec Jan Feb Mar Apr May June\n",
    "def date_revision(date):\n",
    "    if date <= -1:\n",
    "        return 'Sep'\n",
    "    elif date <= 31:\n",
    "        return 'Oct'\n",
    "    elif date <= 61:\n",
    "        return 'Nov'\n",
    "    elif date <= 92:\n",
    "        return 'Dec'\n",
    "    elif date <= 123:\n",
    "        return 'Jan'\n",
    "    elif date <= 151:\n",
    "        return 'Feb'\n",
    "    elif date <= 179:\n",
    "        return 'Mar'\n",
    "    elif date <= 210:\n",
    "        return 'Apr'\n",
    "    elif date <= 240:\n",
    "        return 'May'\n",
    "    else:\n",
    "        return 'Jun'\n",
    "    \n",
    "def date_number(date):\n",
    "    if date == 'Sep':\n",
    "        return 1\n",
    "    elif date == 'Oct':\n",
    "        return 2\n",
    "    elif date == 'Nov':\n",
    "        return 3\n",
    "    elif date == 'Dec':\n",
    "        return 4\n",
    "    elif date == 'Jan':\n",
    "        return 5\n",
    "    elif date == 'Feb':\n",
    "        return 6\n",
    "    elif date == 'Mar':\n",
    "        return 7\n",
    "    elif date == 'Apr':\n",
    "        return 8\n",
    "    elif date == 'May':\n",
    "        return 9\n",
    "    else:\n",
    "        return 10\n",
    "\n",
    "studentRegistration['reg_month'] = studentRegistration['date_registration'].apply(date_revision)\n",
    "studentRegistration['unreg_month'] = studentRegistration['date_unregistration'].apply(date_revision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the date registration\n",
    "\n",
    "g = sns.countplot(x ='reg_month', \n",
    "              data = studentRegistration,\n",
    "              color='grey',\n",
    "              order = studentRegistration.reg_month.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Student Registration Date (Month)', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99% of registrations took place in September."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the date registration\n",
    "\n",
    "g = sns.countplot(x ='unreg_month', \n",
    "              data = studentRegistration,\n",
    "              color='grey',\n",
    "              order = studentRegistration.unreg_month.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Student Unregistration Date (Month)', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "69% of students unregistered in June which makes sense because 31% of students dropped out of their course. Most dropouts occur in the first term with a steady number every other month of the year. The lowest dropout rate was in May. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see whether registration months varied across module types\n",
    "\n",
    "pd.crosstab(studentRegistration['code_module'], studentRegistration['reg_month']).plot.barh(stacked = True);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only module BBB, DDD, FFF and GGG had students registering in October, but that was a minority of students. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see whether unregistration months varied across module types\n",
    "\n",
    "\n",
    "g= sns.catplot(y= 'unreg_month', col='code_module', col_wrap=4,\n",
    "                data=studentRegistration[studentRegistration.unreg_month.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Unregistrations per Module per Month', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that AAA has no dropouts and module GGG has very few."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VLE Interactions (studentVle table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The studentVle.csv file contains information about each student’s interactions with the materials in the VLE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load vle_interaction table\n",
    "try:\n",
    "    vle_interaction = pd.read_csv('studentVle.csv')\n",
    "    print(\"The 'vle_interaction' table has {} samples with {} features each.\".format(*vle_interaction.shape))\n",
    "    display(vle_interaction.info())\n",
    "    display(vle_interaction.head())\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "                Feature Description\n",
    "\n",
    "code_module – an identification code for a module.\n",
    "\n",
    "code_presentation - the identification code of the module presentation.\n",
    "\n",
    "id_student – a unique identification number for the student.\n",
    "\n",
    "id_site - an identification number for the VLE material.\n",
    "\n",
    "date – the date of student’s interaction with the material measured as the number of days since the start of the module-presentation.\n",
    "\n",
    "sum_click – the number of times a student interacts with the material in that day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There is evidence of dupliation in the data. Check what percentage of values are duplicated.\n",
    "\n",
    "print(\"Percentage of duplicated values in vle_interaction  \", vle_interaction.duplicated().sum() * 100 / len(vle_interaction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since a student can click on the same material more than once a day, duplicates will be retained but aggregated into a total clicks column later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see how many vle material in each module.\n",
    "g = sns.countplot(x ='code_module', \n",
    "              data = vle_interaction,\n",
    "              color='grey',\n",
    "              order = vle_interaction.code_module.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('VLE interaction per Module', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modules BBB, DDD, FFF may have a heavier workload because there is more VLE interaction than other modules. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column to indicate the average clicks per student\n",
    "\n",
    "from statistics import mean\n",
    "\n",
    "mean_click_per_student = vle_interaction\\\n",
    ".groupby(['code_module', 'code_presentation', 'id_student'])\\\n",
    ".agg(AVG_click = (\"sum_click\", mean))\\\n",
    ".reset_index()\n",
    "\n",
    "mean_click_per_student = mean_click_per_student.round(0)\n",
    "\n",
    "mean_click_per_student.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.countplot(x ='AVG_click', \n",
    "              data = mean_click_per_student,\n",
    "              color='grey',\n",
    "              order = mean_click_per_student.AVG_click.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8') \n",
    "g.set_xticklabels(['3', '2', '4', '5', '6', '1', '7', '8', '', '', '', '', '', '', '', '', '', '', ''])\n",
    "g.set_title('Average VLE Interaction', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most students clicked on the material three times per day. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column to indicate the total clicks per student\n",
    "\n",
    "total_click_per_student = vle_interaction\\\n",
    ".groupby(['code_module', 'code_presentation', 'id_student'])\\\n",
    ".agg(total_click = (\"sum_click\",sum))\\\n",
    ".reset_index()\n",
    "\n",
    "total_click_per_student.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge mean_click_per_student and total_click_per_student tables together \n",
    "\n",
    "total_click_per_student = pd.merge(total_click_per_student ,  mean_click_per_student , on=['code_module', 'code_presentation', 'id_student'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge total_click_per_student and vle_interaction tables together\n",
    "\n",
    "vle_interaction = pd.merge(total_click_per_student , vle_interaction, on=['code_module', 'code_presentation', 'id_student'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge vle_interaction and Vle tables together to get a better idea of student activity\n",
    "\n",
    "vle_interaction = vle_interaction.merge(materials[['id_site', 'activity_type']], on='id_site', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the overall activity (total clicks) per activity type\n",
    "\n",
    "overall_activity = pd.DataFrame(vle_interaction.groupby(['activity_type'])['sum_click'].sum()).reset_index()\n",
    "overall_activity['percentage'] = round(overall_activity['sum_click'] / overall_activity['sum_click'].sum() * 100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the most common activity type\n",
    "\n",
    "# sort df by sum_click column\n",
    "overall_activity = overall_activity.sort_values(['sum_click']).reset_index(drop=True)\n",
    "print (overall_activity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OU content, foruming, quiz and homepage are the most common VLE activities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.barplot(overall_activity.index, overall_activity.sum_click, color='grey')\n",
    "g.get_yaxis().set_major_formatter(plt.FuncFormatter(lambda x, loc: \"{:,}\".format(int(x))))\n",
    "g.set(xlabel=\"activity_type\", ylabel='sum_click')\n",
    "# add proper Dim values as x labels\n",
    "g.set_xticklabels(overall_activity.activity_type)\n",
    "for item in g.get_xticklabels(): item.set_rotation(90)\n",
    "patch_h = []\n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Most Common VLE Activity', fontsize = 18)\n",
    "print(\"Count plots for VLE Activity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the date to month for visualisation\n",
    "\n",
    "vle_interaction['month'] = vle_interaction['date'].apply(date_revision)\n",
    "vle_interaction['month_no'] = vle_interaction['month'].apply(date_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store month, month_no and sum_clicks to visualise activity\n",
    "\n",
    "studentVle_merge_A_df = pd.DataFrame(vle_interaction.groupby(['month','month_no'])['sum_click'].sum())\n",
    "studentVle_merge_A_df.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by month number\n",
    "\n",
    "studentVle_merge_A_df = studentVle_merge_A_df.sort_values('month_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig= plt.figure(figsize=(10,6)) \n",
    "ax1 = plt.plot( 'month', 'sum_click', data=studentVle_merge_A_df, marker='', color='#003366', linewidth=2)\n",
    "plt.axvspan('Apr', 'May', color='#cccccc', alpha=0.25)\n",
    "plt.legend(labels =['All Students'])\n",
    "plt.ylabel('No. of Clicks', fontsize=10)\n",
    "plt.title('VLE Engagement Over Time', loc='center',pad=15, fontsize=15);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most activity occurred in October and the least in June."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which won't provide any extra information after grouping by module presentation per student.\n",
    "vle_interaction.drop(columns=['id_site', 'date', 'activity_type'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe which merges vle_interaction with student info to chart the VLE engagement of\n",
    "# distinction and failing students\n",
    "\n",
    "student_outcome = pd.merge(vle_interaction, studentInfo, on=['code_module', 'code_presentation', 'id_student'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_outcome.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a subset of the required columns\n",
    "\n",
    "student_outcome = student_outcome[['final_result', 'month', 'month_no', 'sum_click']]\n",
    "student_outcome =student_outcome.sort_values('month_no')\n",
    "student_outcome.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast distinction vs non-distinction\n",
    "\n",
    "distinction = student_outcome['final_result'] == 'Distinction'\n",
    "studentVle_merge_A_df = pd.DataFrame(student_outcome[distinction].groupby(['month','month_no'])['sum_click'].sum())\n",
    "studentVle_merge_A_df.reset_index(inplace = True)\n",
    "\n",
    "nodistinction = student_outcome['final_result'] != 'Distinction'\n",
    "studentVle_merge_NA_df = pd.DataFrame(student_outcome[nodistinction].groupby(['month','month_no'])['sum_click'].sum())\n",
    "studentVle_merge_NA_df.reset_index(inplace = True)\n",
    "studentVle_merge_NA_df['sum_click'] = round(studentVle_merge_NA_df['sum_click'] / 16)\n",
    "studentVle_merge_NA_df\n",
    "\n",
    "\n",
    "studentVle_merge_A_df = studentVle_merge_A_df.sort_values('month_no')\n",
    "studentVle_merge_NA_df = studentVle_merge_NA_df.sort_values('month_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display visualisation\n",
    "\n",
    "fig= plt.figure(figsize=(10,6)) \n",
    "ax1 = plt.plot( 'month', 'sum_click', data=studentVle_merge_A_df, marker='', color='#003366', linewidth=2)\n",
    "ax2 = plt.plot( 'month', 'sum_click', data=studentVle_merge_NA_df, marker='', color='#cccccc', linewidth=2)\n",
    "plt.axvspan('Apr', 'May', color='#cccccc', alpha=0.25)\n",
    "plt.legend(labels =['Distinction','Non-Distinction'])\n",
    "plt.ylabel('No. of Clicks', fontsize=10)\n",
    "plt.title('VLE Interaction of Distinction Students', loc='center',pad=15, fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'student_failed' column which indicates whether the student failed the course. \n",
    "# '0' : Did not fail, '1': 'Failed'\n",
    "\n",
    "student_outcome['student_failed'] = [1 if result in ['Distinction', 'Pass'] else 0  for result in student_outcome['final_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast Fail vs Not Fail\n",
    "\n",
    "Fail = student_outcome['student_failed'] == 0\n",
    "studentVle_merge_A_df = pd.DataFrame(student_outcome[Fail].groupby(['month','month_no'])['sum_click'].sum())\n",
    "studentVle_merge_A_df.reset_index(inplace = True)\n",
    "\n",
    "noFail = student_outcome['student_failed'] == 1\n",
    "studentVle_merge_NA_df = pd.DataFrame(student_outcome[noFail].groupby(['month','month_no'])['sum_click'].sum())\n",
    "studentVle_merge_NA_df.reset_index(inplace = True)\n",
    "studentVle_merge_NA_df['sum_click'] = round(studentVle_merge_NA_df['sum_click'] / 16)\n",
    "studentVle_merge_NA_df\n",
    "\n",
    "studentVle_merge_A_df = studentVle_merge_A_df.sort_values('month_no')\n",
    "studentVle_merge_NA_df = studentVle_merge_NA_df.sort_values('month_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the chart\n",
    "\n",
    "fig= plt.figure(figsize=(10,6)) \n",
    "ax1 = plt.plot( 'month', 'sum_click', data=studentVle_merge_A_df, marker='', color='#003366', linewidth=2)\n",
    "ax2 = plt.plot( 'month', 'sum_click', data=studentVle_merge_NA_df, marker='', color='#cccccc', linewidth=2)\n",
    "plt.axvspan('Apr', 'May', color='#cccccc', alpha=0.25)\n",
    "plt.legend(labels =['Did not Fail','Failed'])\n",
    "plt.ylabel('No. of Clicks', fontsize=10)\n",
    "plt.title('VLE Engagement of Failing Students', loc='center',pad=15, fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'student_withdrew' column which indicates whether the student withdrew from the course. \n",
    "# '0' : Did not withdraw, '1': 'withdrew'\n",
    "\n",
    "student_outcome['student_Withdrawn'] = [1 if result in ['Withdrawn'] else 0  for result in student_outcome['final_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contrast Withdrawn vs completed course\n",
    "\n",
    "Withdrawn = student_outcome['student_Withdrawn'] == 1\n",
    "studentVle_merge_A_df = pd.DataFrame(student_outcome[Withdrawn].groupby(['month','month_no'])['sum_click'].sum())\n",
    "studentVle_merge_A_df.reset_index(inplace = True)\n",
    "\n",
    "noWithdrawn = student_outcome['student_Withdrawn'] == 0\n",
    "studentVle_merge_NA_df = pd.DataFrame(student_outcome[noWithdrawn].groupby(['month','month_no'])['sum_click'].sum())\n",
    "studentVle_merge_NA_df.reset_index(inplace = True)\n",
    "studentVle_merge_NA_df['sum_click'] = round(studentVle_merge_NA_df['sum_click'] / 16)\n",
    "studentVle_merge_NA_df\n",
    "\n",
    "studentVle_merge_A_df = studentVle_merge_A_df.sort_values('month_no')\n",
    "studentVle_merge_NA_df = studentVle_merge_NA_df.sort_values('month_no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the chart\n",
    "\n",
    "fig= plt.figure(figsize=(10,6)) \n",
    "ax1 = plt.plot( 'month', 'sum_click', data=studentVle_merge_A_df, marker='', color='#003366', linewidth=2)\n",
    "ax2 = plt.plot( 'month', 'sum_click', data=studentVle_merge_NA_df, marker='', color='#cccccc', linewidth=2)\n",
    "plt.axvspan('Apr', 'May', color='#cccccc', alpha=0.25)\n",
    "plt.legend(labels =['Withdrew','Completed Course'])\n",
    "plt.ylabel('No. of Clicks', fontsize=10)\n",
    "plt.title('VLE Engagement of Dropouts', loc='center',pad=15, fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns \n",
    "vle_interaction.drop(columns=['month', 'month_no'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate values because it will overly complicate the grade prediction process if a student is included more than once\n",
    "\n",
    "vle_interaction = vle_interaction.drop_duplicates(subset='id_student', keep= 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vle_interaction.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CREATING THE FINAL DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merging Tables Together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Merge the studentRegistration table with the Courses table using an inner join into regCourses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with an inner join\n",
    "regCourses = pd.merge(studentRegistration , courses, on=['code_module', 'code_presentation'], how='inner')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge regCourses with the studentInfo table using an inner join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with an inner join\n",
    "regCoursesInfo = pd.merge(regCourses, studentInfo, on=['code_module', 'code_presentation', 'id_student'], how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge assessments and results tables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge with an inner join\n",
    "assResults = pd.merge(assessments, results, on=['id_assessment'], how='inner')\n",
    "# Rearrange column names\n",
    "assResults = assResults[['id_student', 'code_module', 'code_presentation', 'id_assessment', 'assessment_type', 'date', 'date_submitted', 'weight', 'is_banked', 'score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating New Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a Weighted Score so that the total weight of all modules can be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of dataset\n",
    "scores = assResults\n",
    "\n",
    "# Count how many exams there are in Results for every module presentation\n",
    "scores[scores['assessment_type'] == 'Exam'][['code_module', 'code_presentation', 'id_assessment']]\\\n",
    ".groupby(['code_module', 'code_presentation'])\\\n",
    ".nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CCC module only has results for 1 exam when the module should have 2 exams in total.\n",
    "\n",
    "DDD module has results for the final exam (DDD module should have one exam in total)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Make helper columns ###\n",
    "# (a) Add column multiplying weight and score\n",
    "scores['weight*score'] = scores['weight']*scores['score']\n",
    "# (b) Aggregate recorded weight*score per student\n",
    "    # per module presentation\n",
    "sum_scores = scores\\\n",
    ".groupby(['id_student', 'code_module', 'code_presentation'])\\\n",
    ".agg(weightByScore = ('weight*score', sum))\\\n",
    ".reset_index()\n",
    "# (c) Calculate total recorded weight of module\n",
    "# (c.i) Get total weight of modules\n",
    "total_weight = assessments\\\n",
    ".groupby(['code_module', 'code_presentation'])\\\n",
    ".agg(total_weight = ('weight', sum))\\\n",
    ".reset_index()\n",
    "# (c.ii) Subtract 100 to account for missing exams\n",
    "total_weight['total_weight'] = total_weight['total_weight']-100\n",
    "# (c.iii) Mark module DDD as having 200 credits \n",
    "total_weight.loc[(total_weight.code_module == 'DDD'), 'total_weight'] = 200\n",
    "\n",
    "### Calculate weighted score ###\n",
    "# (a) Merge sum_scores and total_weight tables\n",
    "score_weights = pd.merge(sum_scores, total_weight, on=['code_module', 'code_presentation'], how='inner')\n",
    "# (b) Calculate weighted score\n",
    "score_weights['weighted_score'] = score_weights['weightByScore'] / score_weights['total_weight']\n",
    "# (c) Drop helper columns\n",
    "score_weights.drop(columns=['weightByScore', 'total_weight'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_weights.head(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a late_rate_per_student to indicate what percentage of assignments were submitted late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the difference between the submission dates\n",
    "lateSubmission = assResults.assign(submission_days=assResults['date_submitted']-assResults['date'])\n",
    "# Make a column indicating if the submission was late or not \n",
    "lateSubmission = lateSubmission.assign(late_submission=lateSubmission['submission_days'] > 0)\n",
    "\n",
    "# Aggregate per student per module presentation\n",
    "total_late_per_student = lateSubmission\\\n",
    ".groupby(['id_student', 'code_module', 'code_presentation'])\\\n",
    ".agg(total_late_submission = ('late_submission', sum))\\\n",
    ".reset_index()\n",
    "\n",
    "# Make a df with total number of all assessments per student per module presentation\n",
    "total_count_assessments = lateSubmission[['id_student', 'code_module', 'code_presentation', 'id_assessment']]\\\n",
    ".groupby(['id_student', 'code_module', 'code_presentation'])\\\n",
    ".size()\\\n",
    ".reset_index(name='total_assessments')\n",
    "\n",
    "# Merge df with total late assessements and total count assessments\n",
    "late_rate_per_student = pd.merge(total_late_per_student, total_count_assessments, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "# Make a new column with late submission rate\n",
    "late_rate_per_student['late_rate'] = late_rate_per_student['total_late_submission'] / late_rate_per_student['total_assessments']\n",
    "\n",
    "\n",
    "late_rate_per_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat null values in the late_rate column as 100% late \n",
    "# because they did not make any submission\n",
    "\n",
    "late_rate_per_student = late_rate_per_student.replace(np.nan).fillna(1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a fail_rate_per_student to indicate what percentage of assignments were submitted late"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for marking failed assignments\n",
    "passRate = assResults\n",
    "passRate = passRate.assign(fail=passRate['score'] < 40)\n",
    "\n",
    "# Aggregate per student per module presentation\n",
    "total_fails_per_student = passRate\\\n",
    ".groupby(['id_student', 'code_module', 'code_presentation'])\\\n",
    ".agg(total_fails = (\"fail\",sum))\\\n",
    ".reset_index()\n",
    "\n",
    "total_fails_per_student.head()\n",
    "\n",
    "# Merge df with total fails and total count assessments\n",
    "fail_rate_per_student = pd.merge(total_fails_per_student, total_count_assessments, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "# Make a new column with late submission rate\n",
    "fail_rate_per_student['fail_rate'] = fail_rate_per_student['total_fails'] / fail_rate_per_student['total_assessments']\n",
    "# Drop helper columns\n",
    "fail_rate_per_student.drop(columns=['total_fails', 'total_assessments'], inplace=True)\n",
    "\n",
    "fail_rate_per_student"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge All Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Merge assessment table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assessments = pd.merge(score_weights, late_rate_per_student, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "assessments = pd.merge(assessments, fail_rate_per_student, on=['id_student', 'code_module', 'code_presentation'], how='inner')\n",
    "\n",
    "assessments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(regCoursesInfo, vle_interaction, on=['id_student', 'code_module', 'code_presentation'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(merged, assessments, on=['id_student', 'code_module', 'code_presentation'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column called 'procrastination' which notes whether a student has less than the \n",
    "# average number of VLE clicks and at least one late submission\n",
    "\n",
    "data['procrastination'] = ((data.iloc[:,18:19] < 3.0) | (data.iloc[:,23:24] > 0.0)).any(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['procrastination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['procrastination'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most students were not procrastinating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " print(\"The final dataset has {} samples with {} features each.\".format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******************************"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format the dataset and send to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the columns so that id_student is listed first\n",
    "\n",
    "col_list = list(data.columns)\n",
    "col_list.insert(0,col_list.pop(col_list.index('id_student')))\n",
    "data = data.loc[:,col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new csv file containing the final dataset\n",
    "\n",
    "data.to_csv('oulad_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
