{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4730bfae",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dbs.ie/images/default-source/logos/dbs-logo-2019-small.png\" align = left/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc9b227",
   "metadata": {},
   "source": [
    "#  Open University Learning Analytics Dataset Cleaning\n",
    "\n",
    "Capstone Project\n",
    "\n",
    "Claire Connaughton (10266499)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9630d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "plotnine.options.figure_size = (5.2,3.2)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import interp\n",
    "from scipy.stats import skew, norm, probplot, boxcox, f_oneway\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from collections import Counter\n",
    "from pandas_profiling import ProfileReport\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018be1c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c5b56",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63e1fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load OULA dataset\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('oulad_final.csv')\n",
    "    print(\"The 'OULA' dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedea50e",
   "metadata": {},
   "source": [
    "# Describe Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025ab5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9648a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the datatype of 'id_student' from int to object\n",
    "\n",
    "data['id_student'] = data['id_student'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a9aa03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date_registration and date_unregistration columns since the information is\n",
    "# already captured in the monthly format\n",
    "data.drop(columns=['date_registration', 'date_unregistration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7397821",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b1bac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "132dc3bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ProfileReport(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da458067",
   "metadata": {},
   "source": [
    "The initial inspection of the data has revealed some data quality issues including missing values, highly correlated columns and categorical variables which need to be treated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81832bdc",
   "metadata": {},
   "source": [
    "# Verify Data Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202dab12",
   "metadata": {},
   "source": [
    "Check for Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8f1a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(data):\n",
    "        mis_val = data.isnull().sum()\n",
    "        mis_val_percent = 100 * data.isnull().sum() / len(data)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"The OULA dataset has \" + str(data.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55537f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7349a00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat weighted_score column by replacing null values with 0 because those students did not make any submissions\n",
    "\n",
    "data['weighted_score'] = data['weighted_score'].replace(np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ff7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat null values in the total_late_submission column as 100% late because they did not make any late submission\n",
    "\n",
    "data['total_late_submission'] = data['total_late_submission'].replace(np.nan).fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6e908d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get median total_assignments\n",
    "data.total_assessments.median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a57f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace total_assessments NaNs with median number\n",
    "data['total_assessments'] = np.where( (data['total_assessments'].isnull()),\n",
    "                                           data.total_assessments.median(),\n",
    "                                           data['total_assessments']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb5c0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat null values in the late_rate column as 100% late because they did not make any late submission\n",
    "\n",
    "data['late_rate'] = data['late_rate'].replace(np.nan).fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51314583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat null values in the fail_rate column as 100% failed \n",
    "# because they did not make any submission\n",
    "\n",
    "data['fail_rate'] = data['fail_rate'].replace(np.nan).fillna(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe92c4f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the Total_click column by replacing null values with 0 because those students did not interact with the VLE.\n",
    "\n",
    "data['total_click'] = data['total_click'].replace(np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d8233f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the AVG_click column by replacing null values with 0 because those students did not interact with the VLE.\n",
    "\n",
    "data['AVG_click'] = data['AVG_click'].replace(np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d77e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat the sum_click column by replacing null values with 0 because those students did not interact with the VLE.\n",
    "\n",
    "data['sum_click'] = data['sum_click'].replace(np.nan).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7262043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To treat the missing imd_band values, first find what is the most frequent band in each region\n",
    "regions_list = list(data\\\n",
    "                    [data['imd_band'].isnull()]['region']\\\n",
    "                    .unique())\n",
    "\n",
    "for i in regions_list:\n",
    "    result = data[data['region'] == i].imd_band.mode()\n",
    "    print(f'{i} IMD band : \\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac799475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all null values with respective most frequent imd_bands\n",
    "regions_list = list(data\\\n",
    "                    [data['imd_band'].isnull()]['region']\\\n",
    "                    .unique())\n",
    "\n",
    "for i in regions_list:\n",
    "    data['imd_band'] = np.where( ( (data['imd_band'].isnull()) & (data['region'] == i) ),\n",
    "                                           data[data['region'] == i].imd_band.mode(),\n",
    "                                           data['imd_band']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6383c183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that there are no null values\n",
    "\n",
    "missing_values_table(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "345894cb",
   "metadata": {},
   "source": [
    "All null values have been successfully treated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f172fb8",
   "metadata": {},
   "source": [
    "**********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cf54b8",
   "metadata": {},
   "source": [
    "Check for duplicate values and treat if required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b1be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of duplicated values in OULA is \", data.duplicated().sum() * 100 / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca476148",
   "metadata": {},
   "source": [
    "There are no duplicated values in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c60d73",
   "metadata": {},
   "source": [
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9973ef",
   "metadata": {},
   "source": [
    "# Numeric Variable Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154d95db",
   "metadata": {},
   "source": [
    "Check the distribution for the numeric variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a723919",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with just numeric variables. \n",
    "# Drop the procrastination column because it is a binary variable. \n",
    "\n",
    "df_num = data.select_dtypes(include=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85616032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create statistics summaries with skew, mean, and median with just numerical columns\n",
    "\n",
    "\n",
    "for col in df_num.columns:\n",
    "\n",
    "    skew = df_num[col].skew()\n",
    "    mean = df_num[col].mean()\n",
    "    median = df_num[col].median()\n",
    "    \n",
    "    print(f'\\tSummary for {col.upper()}')\n",
    "    print(f'Skewness of {col}\\t: {skew}')\n",
    "    print(f'Mean {col} :\\t {mean}')\n",
    "    print(f'Median {col} :\\t {median} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e358af",
   "metadata": {},
   "source": [
    "Every variable has some amount of skewness. Inpsect this futher using distplots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6e4530",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create  dist plots\n",
    "fig,ax =plt.subplots(ncols=6,nrows=2,figsize =(20,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "\n",
    "for col,value in df_num.items ():\n",
    "    if col !=\"Type\":\n",
    "        sns.distplot(value,ax =ax[index])\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e06cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns which are more categorical than continuous\n",
    "\n",
    "df_num.drop(columns=['num_of_prev_attempts', 'total_assessments', 'total_late_submission' ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32df973",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check box plots for outliers\n",
    "\n",
    "#create  boxplots\n",
    "fig,ax =plt.subplots(ncols=4,nrows=2,figsize =(20,10))\n",
    "index = 0\n",
    "ax = ax.flatten()\n",
    "\n",
    "for col,value in df_num.items ():\n",
    "    if col !=\"Type\":\n",
    "        sns.boxplot(y=col,data=df_num,ax =ax[index])\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d050ecd",
   "metadata": {},
   "source": [
    "Evidence of outliers in most of the boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bed032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Complete Log transformation on the skewed target variable, weighted_score\n",
    "\n",
    "weighted_score_log=np.log(data[\"weighted_score\"])\n",
    "print (\"Log normalised skweness for weighted_score is\" , weighted_score_log.skew())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea2a268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for evidence of multicollinearity using a correlation heatmap\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(df_num.corr(), annot=True, cmap=\"coolwarm\", );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169dc9cc",
   "metadata": {},
   "source": [
    "Total_click and Average_click are the most correlated (0.56). Total_click and weighted_score are then next most correlated (0.36).\n",
    "\n",
    "Weighted_score is negatively correlated with fail_rate(-0.37) and late_rate(-0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9b2d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see which features are strongly correlated with weighted score\n",
    "\n",
    "df_num\\\n",
    ".drop(columns=['weighted_score'])\\\n",
    ".corrwith(df_num['weighted_score']).plot.bar(\n",
    "        figsize = (6, 4), title = \"Correlation with Weighted Score\", fontsize = 12,\n",
    "        rot = 90, grid = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f709b3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corrwith(data['weighted_score']).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da36d5da",
   "metadata": {},
   "source": [
    "Weighted_score is most strongly positively correlated with total_assessments and total_click and weakly correlated with fail_rate and late_rate.\n",
    "\n",
    "The procrastination variable does not seem to add more value as it is less correlated than late_rate. Therefore, it may need to be dropped. There is no correlation between module_presentation_length or sum_click with weighted_score so they should be dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e50d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['sum_click', 'module_presentation_length'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0eba3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check that the three columns have been dropped \n",
    "\n",
    "print(\"The 'OULA' dataset has {} samples with {} features each.\".format(*data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e7b8839",
   "metadata": {},
   "source": [
    "# Categorial Variable Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67bdd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce a dataframe with just categorical columns\n",
    "\n",
    "categoricals= data.select_dtypes(exclude=np.number)\n",
    "\n",
    "# Drop id_student because it will not add to the analysis\n",
    "\n",
    "categoricals = categoricals.drop(['id_student'], axis = 1)\n",
    "\n",
    "categoricals.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c287500",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3a8d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the categorical variables which need to be collapsed \n",
    "\n",
    "fig, ax = plt.subplots(1,3, figsize=(15, 5))\n",
    "\n",
    "sns.countplot(categoricals.code_module, ax=ax[0], palette=\"Blues_d\")\n",
    "sns.countplot(categoricals.code_presentation, ax=ax[1], palette=\"Blues_d\")\n",
    "sns.countplot(categoricals.age_band, ax=ax[2], palette=\"Blues_d\")\n",
    "\n",
    "print(\"Count plots for code_module, code_presentation, age_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09703eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "sns.countplot(y= \"region\", data= categoricals, palette=\"Blues_d\")\n",
    "\n",
    "print(\"Count plot for region\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaefafd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "sns.countplot(y= \"highest_education\", data= categoricals, palette=\"Blues_d\")\n",
    "\n",
    "print(\"Count plot for highest_education\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f4142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize=(7, 3))\n",
    "\n",
    "sns.countplot(y= \"imd_band\", data= categoricals, palette=\"Blues_d\")\n",
    "\n",
    "print(\"Count plot for imd_band\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb8707f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Highest Education category\n",
    "\n",
    "# Rename 'no formal quals' into 'lower than a level'\n",
    "data['highest_education'] = np.where( (data['highest_education'] == 'No Formal quals'),\n",
    "                                           'Lower Than A Level',\n",
    "                                           data['highest_education']\n",
    "                                    )\n",
    "\n",
    "# Rename post-grads\n",
    "data['highest_education'] = np.where( (data['highest_education'] == 'Post Graduate Qualification'),\n",
    "                                           'HE Qualification',\n",
    "                                           data['highest_education']\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1caa6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the cleaned categorical variables\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "# Highest Education category\n",
    "g_1 = sns.countplot(y ='highest_education', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.highest_education.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_1.set_title('Highest Education Level Attained', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1998dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 55+ and 35-55 groups with 35+\n",
    "data['age_band'] = np.where( (data['age_band'] == '55<='),\n",
    "                                           '35+',\n",
    "                                           data['age_band']\n",
    "                                    )\n",
    "\n",
    "data['age_band'] = np.where( (data['age_band'] == '35-55'),\n",
    "                                           '35+',\n",
    "                                           data['age_band']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c193593",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the age_band category\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "\n",
    "g_1 = sns.countplot(x ='age_band', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.age_band.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_1.set_title('Age Band of Students', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d1a501",
   "metadata": {},
   "outputs": [],
   "source": [
    "categoricals['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf61e7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothern UK is all Northern England, Scotland and Ireland (assuming Ireland is N.I.)\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'Yorkshire Region'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'North Region'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'Scotland'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "data['region'] = np.where( (data['region'] == 'Ireland'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "# Southern UK is London and all Southern England\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'London Region'),\n",
    "                                           'South UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "data['region'] = np.where( (data['region'] == 'South Region'),\n",
    "                                           'South UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "data['region'] = np.where( (data['region'] == 'South East Region'),\n",
    "                                           'East UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'South West Region'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "# Eastern UK is all Eastern England\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'East Anglian Region'),\n",
    "                                           'East UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'East Midlands Region'),\n",
    "                                           'East UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "# Western UK is Western England and Wales \n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'North Western Region'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'West Midlands Region'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'Wales'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aea9764",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e3f866",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the region category\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "\n",
    "g_1 = sns.countplot(x ='region', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.region.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_1.set_title('Regions', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b551c8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the imd bands\n",
    "\n",
    "data['imd_band'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6545d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three categories: disadvantaged (0-30%), middle class (30-80%), privileged (80-100%)\n",
    "\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '0-10%'),\n",
    "                                           'Disadvantaged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '10-20'),\n",
    "                                           'Disadvantaged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '20-30%'),\n",
    "                                           'Disadvantaged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '30-40%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '40-50%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '50-60%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '60-70%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '70-80%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '80-90%'),\n",
    "                                           'Privileged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '90-100%'),\n",
    "                                           'Privileged',\n",
    "                                           data['imd_band']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab78d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['imd_band'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032c2243",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the imd_band category\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "\n",
    "g_1 = sns.countplot(x ='imd_band', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.imd_band.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_1.set_title('Socio-Economic Status of the Students', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f34b7c",
   "metadata": {},
   "source": [
    "# Target Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec9e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the frequency counts of the final_result column\n",
    "\n",
    "data['final_result'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e9ef09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the 'final_result' category\n",
    "\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "\n",
    "g_1 = sns.countplot(x ='final_result', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.final_result.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g_1.set_title('Final Outcome of the Students', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcf9d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column, 'Dropout', which treats students who withdrew as dropouts\n",
    "# '0' : Not Withdrawn, '1': 'Withdrawn'\n",
    "\n",
    "data['dropout'] = [0 if result in ['Distinction', 'Pass', 'Fail'] else 1 for result in data['final_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5d0342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise student dropouts\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "\n",
    "g_1 = sns.countplot(x ='dropout', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.dropout.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')\n",
    "g_1.set_xticklabels(['Completed Course', 'Dropout'])\n",
    "g_1.set_title('Student Dropouts', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5263b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['dropout'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bd9ddcf",
   "metadata": {},
   "source": [
    "Create a student_failed column to store students who failed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76613c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'student_failed' column which indicates whether the student failed the course. \n",
    "# '0' : Did not fail, '1': 'Failed'\n",
    "\n",
    "data['student_failed'] = [0 if result in ['Distinction', 'Pass', 'Withdrawn'] else 1 for result in data['final_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ddbb28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['student_failed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35922e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise student fails\n",
    "fig, ax = plt.subplots(1,1, figsize=(15, 5))\n",
    "\n",
    "g_1 = sns.countplot(x ='student_failed', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.student_failed.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g_1.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g_1.patches[idx_tallest].set_facecolor('#a834a8')\n",
    "g_1.set_xticklabels(['Did not Fail', 'Failed'])\n",
    "g_1.set_title('Student Fails', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7b6c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the final_result column because it's been collapsed into the 'dropout' and 'student_failed' column\n",
    "\n",
    "data.drop('final_result', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6b6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The 'OULA' dataset has {} samples with {} features each.\".format(*data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71bb0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a1689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new csv file containing the cleaned OULA dataset \n",
    "data.to_csv('oulad_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e7886f",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
