{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce964f70",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dbs.ie/images/default-source/logos/dbs-logo-2019-small.png\" align = left/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1128c7a9",
   "metadata": {},
   "source": [
    "#  Open University Learning Analytics - Student Dropout and Failure for Modules CCC and DDD\n",
    "Capstone Project\n",
    "\n",
    "Claire Connaughton (10266499)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a2f939",
   "metadata": {},
   "source": [
    "*********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7730d6f4",
   "metadata": {},
   "source": [
    " Only two modules have records of the exams: 'DDD' and 'CCC'. Module CCC has two exams. Isolate these modules to extract a result for assignments, exams and overall weighted grade. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafef9b4",
   "metadata": {},
   "source": [
    "# Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dbb005",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "plotnine.options.figure_size = (5.2,3.2)\n",
    "import seaborn as sns\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import interp\n",
    "from scipy.stats import skew, norm, probplot, boxcox, f_oneway\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from collections import Counter\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import dump_svmlight_filefrom sklearn.metrics \n",
    "import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.model_selection import train_test_splitfrom sklearn.utils \n",
    "import resample \n",
    "from imblearn.over_sampling import SMOTE\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ef19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca0cedc",
   "metadata": {},
   "source": [
    "# Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c60ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all of the csv files\n",
    "studentInfo = pd.read_csv('studentInfo.csv')\n",
    "assessments = pd.read_csv('assessments.csv')\n",
    "courses = pd.read_csv('courses.csv')\n",
    "studentAssessment = pd.read_csv('studentAssessment.csv')\n",
    "studentRegistration = pd.read_csv('studentRegistration.csv')\n",
    "studentVle = pd.read_csv('studentVle.csv')\n",
    "vle = pd.read_csv('vle.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61519b79",
   "metadata": {},
   "source": [
    "# Merge Datasets and extract the CCC and DDD modules only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef4ab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge table assessment and table studentAssessment on id_assessment\n",
    "merge_student_ass = pd.merge(assessments, studentAssessment, how='left', on=['id_assessment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef25d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the CCC and DDD module further\n",
    "CCC = merge_student_ass[merge_student_ass['code_module'] == 'CCC']\n",
    "DDD= merge_student_ass[merge_student_ass['code_module'] == 'DDD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b093d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if all assessment data is present for module DDD\n",
    "pd.crosstab(DDD.code_presentation, DDD.assessment_type).plot.barh(stacked = True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4af3bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see if all assessment data is present for module CCC\n",
    "\n",
    "pd.crosstab(CCC.code_presentation, CCC.assessment_type).plot.barh(stacked = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86883c9e",
   "metadata": {},
   "source": [
    "All assessment types are present for module CCC but the data is only available for 2014. \n",
    "\n",
    "Module DDD has no CMA except from in 2013."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0558553",
   "metadata": {},
   "source": [
    "Merge all of the datasets and then filter it to include just the data for module CCC & DDD from 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c368b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with an inner join\n",
    "regCourses = pd.merge(studentRegistration , courses, on=['code_module', 'code_presentation'], how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218a81bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with an inner join\n",
    "regCoursesInfo = pd.merge(regCourses, studentInfo, on=['code_module', 'code_presentation', 'id_student'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55880fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the total_click per student column\n",
    "\n",
    "total_click_per_student = studentVle\\\n",
    ".groupby(['code_module', 'code_presentation', 'id_student'])\\\n",
    ".agg(total_click = (\"sum_click\",sum))\\\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f294a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with other tables\n",
    "\n",
    "merged = pd.merge(regCoursesInfo, total_click_per_student, on=['id_student', 'code_module', 'code_presentation'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1f20de",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf9f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a late_rate column\n",
    "\n",
    "# Calculate the difference between the submission dates\n",
    "lateSubmission = merge_student_ass.assign(submission_days=merge_student_ass['date_submitted']-merge_student_ass['date'])\n",
    "# Make a column indicating if the submission was late or not \n",
    "lateSubmission = lateSubmission.assign(late_submission=lateSubmission['submission_days'] > 0)\n",
    "\n",
    "# Aggregate per student per module presentation\n",
    "total_late_per_student = lateSubmission\\\n",
    ".groupby(['id_student', 'code_module', 'code_presentation'])\\\n",
    ".agg(total_late_submission = ('late_submission', sum))\\\n",
    ".reset_index()\n",
    "\n",
    "# Make a df with total number of all assessments per student per module presentation\n",
    "total_count_assessments = lateSubmission[['id_student', 'code_module', 'code_presentation', 'id_assessment']]\\\n",
    ".groupby(['id_student', 'code_module', 'code_presentation'])\\\n",
    ".size()\\\n",
    ".reset_index(name='total_assessments')\n",
    "\n",
    "# Merge df with total late assessements and total count assessments\n",
    "late_rate_per_student = pd.merge(total_late_per_student, total_count_assessments, on=['id_student', 'code_module', 'code_presentation'], how='left')\n",
    "# Make a new column with late submission rate\n",
    "late_rate_per_student['late_rate'] = late_rate_per_student['total_late_submission'] / late_rate_per_student['total_assessments']\n",
    "\n",
    "late_rate_per_student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3557c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(merged, late_rate_per_student, on=['id_student', 'code_module', 'code_presentation'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12519166",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd4d05ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the unneeded columns in merge_student_ass\n",
    "\n",
    "merge_student_ass.drop(columns=['date_submitted', 'is_banked', 'date' ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd01a974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the merge_studeny_ass table onto the merged table\n",
    "\n",
    "merged = pd.merge(merged, merge_student_ass, on=['id_student', 'code_module', 'code_presentation'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7933890c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out the CCC and DDD modules CCC_DDD\n",
    "\n",
    "CCC = merged[merged['code_module'] == 'CCC']\n",
    "DDD= merged[merged['code_module'] == 'DDD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d7ff51",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [CCC, DDD]\n",
    "\n",
    "CCC_DDD = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1eedfdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCC_DDD.code_module.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bfdf8b",
   "metadata": {},
   "source": [
    "There are more students in the DDD group than the CCC group."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e53de0",
   "metadata": {},
   "source": [
    "Create a new dataframe with just the data from CCC and DDD for 2014 only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc79e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCC_DDD = CCC_DDD.drop(CCC_DDD[CCC_DDD['code_presentation'] == '2013B'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa45268f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCC_DDD = CCC_DDD.drop(CCC_DDD[CCC_DDD['code_presentation'] == '2013J'].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d902ed74",
   "metadata": {},
   "source": [
    "# Calculate Assessment Scores for Module DDD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638350eb",
   "metadata": {},
   "source": [
    "Since module DDD has only an exam and a TMA assignment and module CCC has an exam, TMA and CMA. The weighted grades have to be calculated separately. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e50500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate assignment grade for DDD\n",
    "\n",
    "DDD_assignment = CCC_DDD[(CCC_DDD['code_module'] == 'DDD') & (CCC_DDD['assessment_type'] != 'Exam')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4102a9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_assignment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c408cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the score column as 'assignment score' and 'date_submitted' as 'assignment_sub_date'\n",
    "\n",
    "DDD_assignment.rename(columns = {'score' : 'assignment_score', 'date_submitted': 'assignment_sub_date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e03abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "DDD_assignment.drop(columns=['id_assessment', 'assessment_type', 'weight'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129938f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_assignment.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c032f9",
   "metadata": {},
   "source": [
    "Create the weighted score for the DDD module exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf54c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to just hold exam results for DDD\n",
    "\n",
    "DDD_exams = CCC_DDD[(CCC_DDD['code_module'] == 'DDD') & (CCC_DDD['assessment_type'] == 'Exam')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aef721",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_exams.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdad4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'score column' to 'exam_score' and 'date_submitted' to 'exam_sub_date'\n",
    "\n",
    "DDD_exams.rename(columns = {'score' : 'exam_score', 'date_submitted': 'exam_sub_date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88b7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "DDD_exams.drop(columns=['id_assessment', 'assessment_type', 'weight'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95862687",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_exams.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77aa4cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DDD_assignments and DDD_exams\n",
    "\n",
    "DDD_grades = pd.merge(DDD_assignment, DDD_exams, on=['id_student', 'code_module', 'code_presentation', 'date_registration', 'date_unregistration', 'module_presentation_length', 'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'num_of_prev_attempts', 'studied_credits', 'disability', 'final_result', 'total_click','total_late_submission', 'total_assessments', 'late_rate'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0364bb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_grades.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c68e6afd",
   "metadata": {},
   "source": [
    "Create an overall score for module DDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a0cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Treat nulll values in exam_score\n",
    "# Change all nulls to 0 because that student did not complete the assignment/exam\n",
    "\n",
    "DDD_grades['assignment_score'] = DDD_grades['assignment_score'].replace(np.nan).fillna(0)\n",
    "DDD_grades['exam_score'] = DDD_grades['exam_score'].replace(np.nan).fillna(0)\n",
    "# Create an overall score which combines the assignment and exam scores \n",
    "\n",
    "DDD_grades['overall_score']= (DDD_grades['assignment_score'] * 0.5) + (DDD_grades['exam_score'] * 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f736d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "DDD_grades.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6586db1f",
   "metadata": {},
   "source": [
    "# Calculate Assessment Scores for Module CCC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d86a9d6",
   "metadata": {},
   "source": [
    "Since module DDD does not have a CMA and the CMA is only weighted as 25%, treat the TMA as 100% weighting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd1ef5c",
   "metadata": {},
   "source": [
    "Create a weighted assignment score and exam score for Module CCC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b1af052",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to hold the weighted assignment grade for CCC\n",
    "\n",
    "CCC_assignment = CCC_DDD[(CCC_DDD['code_module'] == 'CCC') & (CCC_DDD['assessment_type'] != 'Exam')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ad2a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the CMA assigments\n",
    "\n",
    "CCC_assignment= CCC_assignment.drop(CCC_assignment[CCC_assignment['assessment_type'] == 'CMA'].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6b2b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the score column as 'assignment score' and 'date_submitted' as 'assignment_sub_date'\n",
    "\n",
    "CCC_assignment.rename(columns = {'score' : 'assignment_score', 'date_submitted': 'assignment_sub_date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cf2566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "CCC_assignment.drop(columns=['id_assessment', 'assessment_type', 'weight'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f37f957",
   "metadata": {},
   "source": [
    "Create a score for the CCC module exams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f212af04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to just hold exam results for DDD\n",
    "\n",
    "CCC_exams = CCC_DDD[(CCC_DDD['code_module'] == 'DDD') & (CCC_DDD['assessment_type'] == 'Exam')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e197ce29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'score column' to 'exam_score' and 'date_submitted' to 'exam_sub_date'\n",
    "\n",
    "CCC_exams.rename(columns = {'score' : 'exam_score', 'date_submitted': 'exam_sub_date'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0e0e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns\n",
    "\n",
    "CCC_exams.drop(columns=['id_assessment', 'assessment_type', 'weight' ], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898c5407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge CCC_assignments and CCC_exams\n",
    "\n",
    "CCC_grades = pd.merge(CCC_assignment, CCC_exams, on=['id_student', 'code_module', 'code_presentation', 'date_registration', 'date_unregistration', 'module_presentation_length', 'gender', 'region', 'highest_education', 'imd_band', 'age_band', 'num_of_prev_attempts', 'studied_credits', 'disability', 'final_result', 'total_click','total_late_submission', 'total_assessments', 'late_rate'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21ae6384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overall score\n",
    "\n",
    "# Treat nulll values in exam_score\n",
    "# Change all nulls to 0 because that student did not complete the assignment/exam\n",
    "\n",
    "CCC_grades['assignment_score'] = CCC_grades['assignment_score'].replace(np.nan).fillna(0)\n",
    "CCC_grades['exam_score'] = CCC_grades['exam_score'].replace(np.nan).fillna(0)\n",
    "# Create an overall score which combines the assignment and exam scores \n",
    "CCC_grades['overall_score']= (CCC_grades['assignment_score'] * 0.33) + (CCC_grades['exam_score'] * 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76479ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "CCC_grades.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a674fc74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an overall score which combines the assignment and exam scores \n",
    "\n",
    "CCC_grades['overall_score']= (CCC_grades['assignment_score'] * 0.33) + (CCC_grades['exam_score'] * 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c875895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DDD_grades and CCC_grades\n",
    "\n",
    "frames= [DDD_grades, CCC_grades]\n",
    "grades = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1b53a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "grades.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9045e639",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb113c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the dataframe from 'grades' to 'data'\n",
    "\n",
    "data=grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b3105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the datatype of 'id_student' from int to object\n",
    "\n",
    "data['id_student'] = data['id_student'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed7b05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the columns so that id_student is listed first\n",
    "\n",
    "col_list = list(data.columns)\n",
    "col_list.insert(0,col_list.pop(col_list.index('id_student')))\n",
    "data = data.loc[:,col_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e007995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop date_registration and date_unregistration columns they are no longer required\n",
    "data.drop(columns=['date_registration', 'date_unregistration'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08556050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "\n",
    "def missing_values_table(data):\n",
    "        mis_val = data.isnull().sum()\n",
    "        mis_val_percent = 100 * data.isnull().sum() / len(data)\n",
    "        mis_val_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mis_val_table_ren_columns = mis_val_table.rename(\n",
    "        columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mis_val_table_ren_columns = mis_val_table_ren_columns[\n",
    "            mis_val_table_ren_columns.iloc[:,1] != 0].sort_values(\n",
    "        '% of Total Values', ascending=False).round(1)\n",
    "        print (\"The OULA dataset has \" + str(data.shape[1]) + \" columns.\\n\"      \n",
    "            \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n",
    "              \" columns that have missing values.\")\n",
    "        return mis_val_table_ren_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01eafbb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ede69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To treat the missing imd_band values, first find what is the most frequent band in each region\n",
    "regions_list = list(data\\\n",
    "                    [data['imd_band'].isnull()]['region']\\\n",
    "                    .unique())\n",
    "\n",
    "for i in regions_list:\n",
    "    result = data[data['region'] == i].imd_band.mode()\n",
    "    print(f'{i} IMD band : \\n', result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace all null values with respective most frequent imd_bands\n",
    "regions_list = list(data\\\n",
    "                    [data['imd_band'].isnull()]['region']\\\n",
    "                    .unique())\n",
    "\n",
    "for i in regions_list:\n",
    "    data['imd_band'] = np.where( ( (data['imd_band'].isnull()) & (data['region'] == i) ),\n",
    "                                           data[data['region'] == i].imd_band.mode(),\n",
    "                                           data['imd_band']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79c952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_values_table(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f156a15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "\n",
    "print(\"Percentage of duplicated values in OULA is \", data.duplicated().sum() * 100 / len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93058728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicated values\n",
    "\n",
    "data= data.drop_duplicates(subset='id_student', keep= 'first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0878eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Percentage of duplicated values in OULA is \", data.duplicated().sum() * 100 / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0866b1",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f19633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the Highest Education category\n",
    "\n",
    "# Rename 'no formal quals' into 'lower than a level'\n",
    "data['highest_education'] = np.where( (data['highest_education'] == 'No Formal quals'),\n",
    "                                           'Lower Than A Level',\n",
    "                                           data['highest_education']\n",
    "                                    )\n",
    "\n",
    "# Rename post-grads\n",
    "data['highest_education'] = np.where( (data['highest_education'] == 'Post Graduate Qualification'),\n",
    "                                           'HE Qualification',\n",
    "                                           data['highest_education']\n",
    "                                    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848c51f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 55+ and 35-55 groups with 35+\n",
    "data['age_band'] = np.where( (data['age_band'] == '55<='),\n",
    "                                           '35+',\n",
    "                                           data['age_band']\n",
    "                                    )\n",
    "\n",
    "data['age_band'] = np.where( (data['age_band'] == '35-55'),\n",
    "                                           '35+',\n",
    "                                           data['age_band']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ca4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nothern UK is all Northern England, Scotland and Ireland (assuming Ireland is N.I.)\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'Yorkshire Region'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'North Region'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'Scotland'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "data['region'] = np.where( (data['region'] == 'Ireland'),\n",
    "                                           'North UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "# Southern UK is London and all Southern England\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'London Region'),\n",
    "                                           'South UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "data['region'] = np.where( (data['region'] == 'South Region'),\n",
    "                                           'South UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "data['region'] = np.where( (data['region'] == 'South East Region'),\n",
    "                                           'East UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'South West Region'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "# Eastern UK is all Eastern England\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'East Anglian Region'),\n",
    "                                           'East UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'East Midlands Region'),\n",
    "                                           'East UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "# Western UK is Western England and Wales \n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'North Western Region'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'West Midlands Region'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )\n",
    "\n",
    "\n",
    "data['region'] = np.where( (data['region'] == 'Wales'),\n",
    "                                           'West UK',\n",
    "                                           data['region']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c817afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three categories: disadvantaged (0-30%), middle class (30-80%), privileged (80-100%)\n",
    "\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '0-10%'),\n",
    "                                           'Disadvantaged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '10-20'),\n",
    "                                           'Disadvantaged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '20-30%'),\n",
    "                                           'Disadvantaged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '30-40%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '40-50%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '50-60%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '60-70%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '70-80%'),\n",
    "                                           'Middle Class',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '80-90%'),\n",
    "                                           'Privileged',\n",
    "                                           data['imd_band']\n",
    "                                    )\n",
    "data['imd_band'] = np.where( (data['imd_band'] == '90-100%'),\n",
    "                                           'Privileged',\n",
    "                                           data['imd_band']\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ab5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column, 'Dropout', which treats students who withdrew as dropouts\n",
    "# '0' : Not Withdrawn, '1': 'Withdrawn'\n",
    "\n",
    "data['dropout'] = [0 if result in ['Distinction', 'Pass', 'Fail'] else 1 for result in data['final_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da6020c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a 'student_failed' column which indicates whether the student failed the course. \n",
    "# '0' : Did not fail, '1': 'Failed'\n",
    "\n",
    "data['student_failed'] = [0 if result in ['Distinction', 'Pass', 'Withdrawn'] else 1 for result in data['final_result']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc79031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the final_result column because it's been collapsed into the 'dropout' and 'student_failed' column\n",
    "\n",
    "data.drop('final_result', axis = 1, inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b1e4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show boxplots for student results of dropouts\n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5)) \n",
    "sns.boxplot(x=\"dropout\", y='assignment_score', ax=ax[0], data=data)\n",
    "sns.boxplot(x=\"dropout\", y='exam_score', ax=ax[1], data=data)\n",
    "sns.boxplot(x=\"dropout\", y='overall_score', ax=ax[2], data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48dd154c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show boxplots for student results of fails \n",
    "fig, ax = plt.subplots(1, 3, figsize=(15, 5)) \n",
    "sns.boxplot(x='student_failed', y='assignment_score', ax=ax[0], data=data)\n",
    "sns.boxplot(x='student_failed', y='exam_score', ax=ax[1], data=data)\n",
    "sns.boxplot(x='student_failed', y='overall_score', ax=ax[2], data=data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a435114b",
   "metadata": {},
   "source": [
    "# Model Preparation for Student Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed84964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "#find design matrix for linear regression model using 'rating' as response variable \n",
    "y, X = dmatrices('student_failed ~ code_module+code_presentation+gender+region+highest_education+imd_band+age_band+num_of_prev_attempts+disability+studied_credits+total_click+late_rate', data=data, return_type='dataframe')\n",
    "\n",
    "#calculate VIF for each explanatory variable\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['variable'] = X.columns\n",
    "\n",
    "#view VIF for each explanatory variable \n",
    "vif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5080b0a8",
   "metadata": {},
   "source": [
    "No variable exceeds the threshold of a VIF score of 5 so all the variables will be retained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679fec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ID column because it's unnecessary for model learning predictions\n",
    "\n",
    "data.drop('id_student', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1efedf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring independent variable i.e X\n",
    "#Declaring Target variable i.e y\n",
    "\n",
    "x = data.drop(['student_failed', 'dropout'], axis = 1)\n",
    "y = data['student_failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b727d087",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# Set encoding and scaling instructions\n",
    "column_transform = make_column_transformer(\n",
    "    (OneHotEncoder(), ['code_presentation', 'gender', 'region', 'age_band', 'disability']),\n",
    "    (OrdinalEncoder(), ['highest_education', 'imd_band']),\n",
    "    (RobustScaler(), ['num_of_prev_attempts', 'studied_credits', 'total_click', 'late_rate'])\n",
    ")\n",
    "\n",
    "# Apply column transformer to features\n",
    "X_encoded = column_transform.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e68a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test dataset\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_encoded, y , test_size = 0.2, random_state  = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2f5f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold \n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdd8497",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample \n",
    "from imblearn.over_sampling import SMOTE \n",
    "smote = SMOTE()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71dea8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sm, y_sm =smote.fit_resample(X_encoded,y) \n",
    "\n",
    "print(X_encoded.shape, y.shape) \n",
    "print(x_sm.shape, y_sm.shape) \n",
    "sns.countplot(y_sm) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff2423b",
   "metadata": {},
   "source": [
    "# Modelling for Student Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e9557a",
   "metadata": {},
   "source": [
    "******************************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239dad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, mean_absolute_error\n",
    "from sklearn import metrics, tree\n",
    "\n",
    "def logistic_regression(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    logreg_model = LogisticRegression() \n",
    "    logreg_model.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = logreg_model.predict(x_train) \n",
    "    pred_test = logreg_model.predict(x_test) \n",
    "    cm_train = confusion_matrix(y_train, pred_train) \n",
    "    cm_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  logreg_model.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bb5a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771008d7",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a16586",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "def decision_tree(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    dt = DecisionTreeClassifier() \n",
    "    dt.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = dt.predict(x_train) \n",
    "    pred_test = dt.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  dt.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f868dfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d99e5d",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fd5693",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "def random_forest(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = rf.predict(x_train) \n",
    "    pred_test = rf.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  rf.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a2dc28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88876079",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0039260",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC \n",
    "\n",
    "def support_vector_machine(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.25, random_state=40, stratify = y) \n",
    "    svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train, y_train) \n",
    "    svm_predictions = svm_model_linear.predict(x_test)\n",
    "\n",
    "    pred_train = svm_model_linear.predict(x_train) \n",
    "    pred_test = svm_model_linear.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  svm_model_linear.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2644dda1",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26425772",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64508c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e624936d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c837d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cb51ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 50  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e112cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing - numpy matrices\n",
    "from sklearn.metrics import precision_score\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7caa6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, best_preds))\n",
    "print(recall_score(y_test, best_preds, average='macro'))\n",
    "print(f1_score(y_test, best_preds, average='macro'))\n",
    "print(precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8662b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(accuracy_score(y_test, best_preds), 3)\n",
    "cm1 = confusion_matrix(y_test, best_preds)\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test,best_preds) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f756355d",
   "metadata": {},
   "source": [
    "# Adding PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bd2bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearnPCA().fit(x_sm)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc5c744",
   "metadata": {},
   "source": [
    "About 12 components explain 95% of the variance in student failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3932424",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pca = sklearnPCA(n_components=12)\n",
    "\n",
    "print(\"===========Data Summary===========\")\n",
    "pca_train_x = sklearn_pca.fit_transform(x_sm)\n",
    "print(\"PCA Training Data :\", pca_train_x.shape)\n",
    "\n",
    "pca_test_x = sklearn_pca.fit_transform(x_sm)\n",
    "print(\"PCA Testing Data :\", pca_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e80bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run logistic regression with PCA\n",
    "\n",
    "logistic_regression(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b59f385",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfce71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958f4458",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4bbe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bf1d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 50  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a737a848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing - numpy matrices\n",
    "from sklearn.metrics import precision_score\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26a2403",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, best_preds))\n",
    "print(recall_score(y_test, best_preds, average='macro'))\n",
    "print(f1_score(y_test, best_preds, average='macro'))\n",
    "print(precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d694090",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(accuracy_score(y_test, best_preds), 3)\n",
    "cm1 = confusion_matrix(y_test, best_preds)\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test,best_preds) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d5ea53",
   "metadata": {},
   "source": [
    "# Predicting Student Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeced86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring independent variable i.e X\n",
    "#Declaring Target variable i.e y\n",
    "\n",
    "x = data.drop(['dropout'], axis = 1)\n",
    "y = data['dropout']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ee4f911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set encoding and scaling instructions\n",
    "column_transform = make_column_transformer(\n",
    "    (OneHotEncoder(), ['code_module', 'code_presentation', 'gender', 'region', 'age_band', 'disability']),\n",
    "    (OrdinalEncoder(), ['highest_education', 'imd_band']),\n",
    "    (RobustScaler(), ['num_of_prev_attempts', 'studied_credits', 'total_click', 'late_rate'])\n",
    ")\n",
    "\n",
    "# Apply column transformer to features\n",
    "X_encoded = column_transform.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25b5f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into train and test dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_encoded, y , test_size = 0.2, random_state  = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7cf95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6fa7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sm, y_sm =smote.fit_resample(X_encoded,y) \n",
    "\n",
    "print(X_encoded.shape, y.shape) \n",
    "print(x_sm.shape, y_sm.shape) \n",
    "sns.countplot(y_sm) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fd9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regression(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "937ef04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a0fcb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf83702",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe732310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 50  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03958b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing - numpy matrices\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e24482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test, best_preds))\n",
    "print(recall_score(y_test, best_preds, average='macro'))\n",
    "print(f1_score(y_test, best_preds, average='macro'))\n",
    "print(precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd395003",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = round(accuracy_score(y_test, best_preds), 3)\n",
    "cm1 = confusion_matrix(y_test, best_preds)\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test,best_preds) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "442f6ea7",
   "metadata": {},
   "source": [
    "# Adding PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3163bc79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearnPCA().fit(x_sm)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e56fcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use 13 principal components\n",
    "sklearn_pca = sklearnPCA(n_components=13)\n",
    "\n",
    "print(\"===========Data Summary===========\")\n",
    "pca_train_x = sklearn_pca.fit_transform(x_sm)\n",
    "print(\"PCA Training Data :\", pca_train_x.shape)\n",
    "\n",
    "pca_test_x = sklearn_pca.fit_transform(x_sm)\n",
    "print(\"PCA Testing Data :\", pca_test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4940194",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-run logistic regression with PCA\n",
    "\n",
    "logistic_regression(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddab3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c060a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3b82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "support_vector_machine(pca_train_x, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6b8fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pca_train_x, y_sm, test_size=0.25)\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')\n",
    "\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 50  # the number of training iterations\n",
    "\n",
    "# training and testing - numpy matrices\n",
    "from sklearn.metrics import precision_score\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "print(accuracy_score(y_test, best_preds))\n",
    "print(recall_score(y_test, best_preds, average='macro'))\n",
    "print(f1_score(y_test, best_preds, average='macro'))\n",
    "print(precision_score(y_test, best_preds, average='macro'))\n",
    "\n",
    "score = round(accuracy_score(y_test, best_preds), 3)\n",
    "cm1 = confusion_matrix(y_test, best_preds)\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test,best_preds) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b5dce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new csv file containing the final dataset for the purpose of ANN\n",
    "\n",
    "data.to_csv('oulad_modelling.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c337314",
   "metadata": {},
   "source": [
    "# Compare Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c30a788",
   "metadata": {},
   "source": [
    "Models to predict student failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7014ddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Bar Chart for Accuracy of different classifiers\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "model_accuracies = [0.84, 0.79, 0.79, 0.74, 0.65, 0.64]\n",
    "model_names = ['RandomForest','XGBoost','ANN - MLP wth PCA', 'Decision Tree', 'Logistic Regression', 'Support Vector Machines' ]\n",
    "g= sns.barplot(x=model_accuracies, y=model_names, color='grey');\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#2ecc71')  \n",
    "g.set_title('Model Accuracy for Student Failure', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7695d9d9",
   "metadata": {},
   "source": [
    "Models to Predict Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b47ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Bar Chart for Accuracy of different classifiers\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "model_accuracies = [0.86, 0.81, 0.80, 0.77, 0.74, 0.74]\n",
    "model_names = ['RandomForest','XGBoost','Decision Tree', 'ANN - MLP wth PCA','Logistic Regression', 'Support Vector Machines' ]\n",
    "g= sns.barplot(x=model_accuracies, y=model_names, color='grey');\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#2ecc71')  \n",
    "g.set_title('Model Accuracy for Student Dropout', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37febf16",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
