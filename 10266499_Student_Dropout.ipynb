{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "45242f68",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dbs.ie/images/default-source/logos/dbs-logo-2019-small.png\" align = left/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351f5f3",
   "metadata": {},
   "source": [
    "#  Open University Learning Analytics - Student Dropout\n",
    "\n",
    "Capstone Project\n",
    "\n",
    "Claire Connaughton (10266499)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9948ef6d",
   "metadata": {},
   "source": [
    "# Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "plotnine.options.figure_size = (5.2,3.2)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import interp\n",
    "from scipy.stats import skew, norm, probplot, boxcox, f_oneway\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from collections import Counter\n",
    "from pandas_profiling import ProfileReport\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import resample \n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, mean_absolute_error\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69573118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f529a",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d37641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned OULA dataset\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('oulad_cleaned.csv')\n",
    "    print(\"The 'Cleaned Dropout OULA' dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e81bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30436199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the columns which are not required for dropout analysis\n",
    "\n",
    "data.drop(columns=['student_failed'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dfbc1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inpsect the number of students who dropped out\n",
    "\n",
    "g = sns.countplot(x ='dropout', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.dropout.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8') \n",
    "g.set_xticklabels(['Completed Course','Dropped Out'])\n",
    "g.set_title('Student Dropouts', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d489d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the code_module column\n",
    "\n",
    "# There are 7 course modules. 4 are from STEM and 3 from Social Sciences\n",
    "# Social Sciences :- AAA, BBB, GGG\n",
    "# STEM :- CCC, DDD, EEE, FFF\n",
    "# Create two categories instead of 7\n",
    "\n",
    "\n",
    "data['code_module'] = ['Social_Science' if data['code_module'].iloc[i] in ['AAA', 'BBB', 'GGG']\n",
    "                                                        else 'STEM' for i in range(len(data))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0747b472",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inpsect the code module category\n",
    "\n",
    "g = sns.countplot(x ='code_module', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.code_module.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('#a834a8')  \n",
    "g.set_title('Code Module', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb2cd95",
   "metadata": {},
   "source": [
    "# Univariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a82fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2f990a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a dataframe with just the categorical variables\n",
    "\n",
    "categoricals= data.select_dtypes(exclude=np.number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a6d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the plot number for the first subplot function\n",
    "plot_number = 1\n",
    "\n",
    "# Set sizes for all plots\n",
    "plt.figure(figsize=(15, 15)) # create a figure object\n",
    "plt.subplots_adjust(hspace = 0.5) # set the size of subplots\n",
    "\n",
    "for col in categoricals:\n",
    "    \n",
    "    # Call countplot on each column\n",
    "    plt.subplot(6, 2, plot_number)\n",
    "    sns.countplot(\n",
    "        y=col,\n",
    "        data=categoricals,\n",
    "        order=categoricals[col].value_counts().index\n",
    "    )\n",
    "    plt.title(f'{col.capitalize()} Countplot')\n",
    "    plt.xlabel('')\n",
    "    plt.ylabel('')\n",
    "\n",
    "    plot_number = plot_number + 1 # set a new plot number for the next subplot function\n",
    "    \n",
    "    # Add relative frequency labels:\n",
    "    n_points = categoricals.shape[0]\n",
    "    col_counts = categoricals[col].value_counts()\n",
    "    locs, labels = plt.yticks()   # get the current tick locations and labels\n",
    "\n",
    "    # loop through each pair of locations and labels\n",
    "    for loc, label in zip(locs, labels):\n",
    "\n",
    "        # get the text property for the label to get the correct count\n",
    "        count = col_counts[label.get_text()]\n",
    "        pct_string = '{:0.1f}%'.format(100*count/n_points)\n",
    "\n",
    "        # print the annotation at the top of the bar\n",
    "        plt.text(x=count, y=loc, s=pct_string, ha='left', va='center', color='k')\n",
    "    \n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed2414da",
   "metadata": {},
   "source": [
    "# Bivariate Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f36678",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb92522c",
   "metadata": {},
   "source": [
    "The results are vague. There doesn't seem to be any strong relationships between any variables and the target except from the number of total clicks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a772d640",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr=data.apply(lambda x:pd.factorize(x)[0]).corr(method='pearson')\n",
    "mask = np.zeros_like(corr)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "f, ax = plt.subplots(figsize=(15, 8))\n",
    "sns.heatmap(corr,annot=True, mask=mask, cmap=\"YlGnBu\")\n",
    "plt.title(\"Multi Variate Correlation Plot\", fontsize=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27e9ad",
   "metadata": {},
   "source": [
    "The stongest positive correlations were between dropout unreg_month (0.8). \n",
    "\n",
    "There were also strong relationships total_late_submission and late_rate (0.43), AVG_click and procrastination (0.46). \n",
    "\n",
    "The highest negative correlation was observed between gender and code_module (-0.56).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c812102",
   "metadata": {},
   "source": [
    "# Bivariate Analysis for Student Dropouts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b073e97b",
   "metadata": {},
   "source": [
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7c3602",
   "metadata": {},
   "source": [
    "# Demographic Details of Students who Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0072ef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the number of dropouts in each module\n",
    "\n",
    "g= sns.catplot(y= 'dropout', col='code_module', col_wrap=4,\n",
    "                data=data[data.code_module.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.set_yticklabels(['Completed Course','Dropout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b625f227",
   "metadata": {},
   "source": [
    "More students dropped out of STEM courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c24ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a gender difference in dropouts\n",
    "\n",
    "g= sns.catplot(y= 'dropout', col='gender', col_wrap=4,\n",
    "                data=data[data.gender.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.set_yticklabels(['Completed Course','Dropout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814e7494",
   "metadata": {},
   "source": [
    "Slightly more males dropped out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec0f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a regional difference in dropouts\n",
    "\n",
    "g= sns.catplot(y= 'dropout', col='region', col_wrap=4,\n",
    "                data=data[data.region.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.set_yticklabels(['Completed Course','Dropout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88e74c5",
   "metadata": {},
   "source": [
    "South UK had fewer dropouts than any other region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030ddd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check if there is difference in highest education level among dropouts\n",
    "\n",
    "g= sns.catplot(y= 'dropout', col='highest_education', col_wrap=4,\n",
    "                data=data[data.highest_education.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_yticklabels(['Completed Course','Dropout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb9c648",
   "metadata": {},
   "source": [
    "Students with a higher education qualification were the least likely to dropout and students with the lowest educational attainment are the most likely to dropout."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39065b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is difference in socio-economic status among dropouts\n",
    "\n",
    "g= sns.catplot(y= 'dropout', col='imd_band', col_wrap=4,\n",
    "                data=data[data.imd_band.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_yticklabels(['Completed Course','Dropout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bfa0343",
   "metadata": {},
   "source": [
    "Socioeconomically disadvantaged students were more likely to dropout. The most economically priviledged students had the lowest dropout rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c1936ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is an age difference among dropouts\n",
    "g= sns.catplot(y= 'dropout', col='age_band', col_wrap=4,\n",
    "                data=data[data.age_band.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_yticklabels(['Completed Course','Dropout'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d364378",
   "metadata": {},
   "source": [
    "Under 35s are the most likely to dropout of their course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9864b2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a difference among student ability groups and dropouts\n",
    "\n",
    "g= sns.catplot(y= 'dropout', col='disability', col_wrap=4,\n",
    "                data=data[data.disability.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_yticklabels(['Completed Course','Dropout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb93918",
   "metadata": {},
   "source": [
    "Students with a disability are more likely to dropout. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f64a6f0",
   "metadata": {},
   "source": [
    "# The demographic profile of students who are more likely to dropout is as follows:\n",
    "\n",
    "1) Under 35s\n",
    "\n",
    "\n",
    "2) Male\n",
    "\n",
    "\n",
    "3) Not being from Northern UK \n",
    "\n",
    "\n",
    "4) Studying a STEM course\n",
    "\n",
    "\n",
    "5) From a lower socio-economic class\n",
    "\n",
    "\n",
    "6) Holding lower than A-Level education\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e984e3",
   "metadata": {},
   "source": [
    "# Behavioural Details of Students who Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c70898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and the number of previous attempts\n",
    "\n",
    "g= sns.catplot(y= 'dropout', col='num_of_prev_attempts', col_wrap=4,\n",
    "                data=data[data.num_of_prev_attempts.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_yticklabels(['Completed Course','Dropout'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e967bcc4",
   "metadata": {},
   "source": [
    "Students who dropped out made more attempts to complete the module. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6432a127",
   "metadata": {},
   "outputs": [],
   "source": [
    "# However, very few students made another attempt\n",
    "\n",
    "g = sns.countplot(x ='num_of_prev_attempts', \n",
    "              data = data,\n",
    "              color='grey',\n",
    "              order = data.num_of_prev_attempts.value_counts().index);\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('c')  \n",
    "g.set_title('Number of Previous Attempts', fontsize = 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed806b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and the number of studied credits\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(y='studied_credits',x='dropout',data=data,palette='Blues_d');\n",
    "plt.title(\"Number of Studied Credits by Dropouts\", fontsize=18);\n",
    "plt.xticks(np.arange(2),('Completed Course','Dropped Out'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c4fcef",
   "metadata": {},
   "source": [
    "The students who dropped out studied more credits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb171a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and the Average number of clicks\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(y='AVG_click',x='dropout',data=data,palette='Blues_d');\n",
    "plt.title(\"Impact AVG Clicks on Dropping Out\", fontsize=18);\n",
    "plt.xticks(np.arange(2),('Completed Course','Dropped Out'));\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da94631f",
   "metadata": {},
   "source": [
    "Students who dropped out had a lower number of average clicks on the Virtual Learning Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a3a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and the total clicks in the VLE\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(y='total_click',x='dropout',data=data,palette='Blues_d');\n",
    "plt.title(\"Impact Total Clicks by Dropouts\", fontsize=18);\n",
    "plt.xticks(np.arange(2),('Completed Course','Dropped Out'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d02ca0",
   "metadata": {},
   "source": [
    "The students who dropped out had considerably fewer total clicks than the students who completed the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c48769f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and late submission of assignments\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(y='late_rate',x='dropout',data=data,palette='Blues_d');\n",
    "plt.title(\"Impact Late Submission on Dropping Out\", fontsize=18);\n",
    "plt.xticks(np.arange(2),('Completed Course','Dropped Out'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb3f389",
   "metadata": {},
   "source": [
    "Students who dropped out were more likely to submit their assignment late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af38ce2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and weighted score\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(y='weighted_score',x='dropout',data=data,palette='Blues_d');\n",
    "plt.title(\"Impact Weighted Score on Dropping Out\", fontsize=18);\n",
    "plt.xticks(np.arange(2),('Completed Course','Dropped Out'));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c08d2a",
   "metadata": {},
   "source": [
    "Students who had lower weighted scores had higher dropout rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf9c26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and the date unregistered\n",
    "\n",
    "# Visulaise the breakdown in module lenght per module type\n",
    "\n",
    "pd.crosstab(data.unreg_month, data.dropout).plot.barh(stacked = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b1a104",
   "metadata": {},
   "source": [
    "Most dropouts occured in the first term."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d5edb1",
   "metadata": {},
   "source": [
    "# The behaviour profile of students who are more likely to dropout is as follows:\n",
    "\n",
    "1) Studied more credits so their workload was higher\n",
    "\n",
    "2) Less inclined to interact with the VLE\n",
    "\n",
    "\n",
    "3) More likely to submit assignments late\n",
    "\n",
    "\n",
    "4) Tended to have lower attainment scores\n",
    "\n",
    "5) Were more likely to dropout in the first term\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b2529ea",
   "metadata": {},
   "source": [
    "**********************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d722f1",
   "metadata": {},
   "source": [
    "# Multivariate Analysis for Student Dropouts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d021e4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NumPy's corrcoef and seaborn's heatmap functions to plot the correlation matrix array as a heat map.\n",
    "\n",
    "corr = data.corr()\n",
    "top_corr_cols = corr.dropout.sort_values(ascending=False).keys() \n",
    "top_corr = corr.loc[top_corr_cols, top_corr_cols]\n",
    "dropSelf = np.zeros_like(top_corr)\n",
    "dropSelf[np.triu_indices_from(dropSelf)] = True\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(top_corr, cmap=sns.diverging_palette(220, 10, as_cmap=True), annot=True, fmt=\".2f\", mask=dropSelf)\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "sns.set(font_scale=1.0)\n",
    "cols = data.columns\n",
    "g = sns.pairplot(data = data.loc[:, cols], hue='dropout')\n",
    "fig = g.fig \n",
    "fig.subplots_adjust(top=0.93, wspace=0.3)\n",
    "t = fig.suptitle('Pairwise Plots by Dropout', fontsize=24)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del corr, dropSelf, top_corr, g, fig, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c130a35b",
   "metadata": {},
   "source": [
    "The multivariate analysis provides further confirmation that the students who dropped out were academically struggling and had lower engagement with the VLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2536b4b",
   "metadata": {},
   "source": [
    "The multivariate analysis also indicates that some columns are providing the same information, such as AVG_click and total_click, total_late_submission and late_rate.\n",
    "\n",
    "These columns should be dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c116e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(columns=['AVG_click', 'total_assessments', 'total_late_submission'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9564fb",
   "metadata": {},
   "source": [
    "# MODEL PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb8ca3f",
   "metadata": {},
   "source": [
    "Checking the Variance Inflation Factor for Each Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09b040a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find design matrix for linear regression model using 'rating' as response variable \n",
    "y, X = dmatrices('dropout ~ code_module+code_presentation+reg_month+unreg_month+gender+region+highest_education+imd_band+age_band+num_of_prev_attempts+disability+studied_credits+total_click+weighted_score+late_rate+fail_rate+procrastination', data=data, return_type='dataframe')\n",
    "\n",
    "#calculate VIF for each explanatory variable\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['variable'] = X.columns\n",
    "\n",
    "#view VIF for each explanatory variable \n",
    "vif\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0733ce8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 5 as the minimum vif values i.e any independent variable 5 and above will have to be dropped\n",
    "# From the results all independent variable are below 5\n",
    "# Drop reg_month column \n",
    "\n",
    "data.drop('reg_month', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379eed6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ID column because it's unnecessary for model learning predictions\n",
    "\n",
    "data.drop('id_student', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e17fb10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring independent variable i.e X\n",
    "#Declaring Target variable i.e y\n",
    "\n",
    "x = data.drop(['dropout'], axis = 1)\n",
    "y = data['dropout']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e0676b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set encoding and scaling instructions\n",
    "column_transform = make_column_transformer(\n",
    "    (OneHotEncoder(), ['code_module', 'code_presentation', 'gender', 'region', 'age_band', 'disability']),\n",
    "    (OrdinalEncoder(), ['highest_education', 'imd_band']),\n",
    "    (RobustScaler(), ['num_of_prev_attempts', 'studied_credits', 'total_click', 'late_rate'])\n",
    ")\n",
    "\n",
    "# Apply column transformer to features\n",
    "X_encoded = column_transform.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19485d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_encoded, y , test_size = 0.2, random_state  = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5509aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up cross validation\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7a870f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SMOTE to treat the imbalanced target variable \n",
    "smote = SMOTE() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f42604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply SMOTE\n",
    "x_sm, y_sm =smote.fit_resample(x_train, y_train) \n",
    "\n",
    "print(x_train.shape, y_train.shape) \n",
    "print(x_sm.shape, y_sm.shape) \n",
    "sns.countplot(y_sm) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69746f53",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9e33d2",
   "metadata": {},
   "source": [
    "**********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ba5ec5",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbea79b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logistic regression model function\n",
    "def logistic_regression(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    logreg_model = LogisticRegression() \n",
    "    logreg_model.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = logreg_model.predict(x_train) \n",
    "    pred_test = logreg_model.predict(x_test) \n",
    "    cm_train = confusion_matrix(y_train, pred_train) \n",
    "    cm_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  logreg_model.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07b8b16a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call logistic regression model\n",
    "\n",
    "logistic_regression(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25381946",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247934cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up decision tree function \n",
    "\n",
    "def decision_tree(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    dt = DecisionTreeClassifier() \n",
    "    dt.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = dt.predict(x_train) \n",
    "    pred_test = dt.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  dt.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e3bf8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call decision tree model\n",
    "decision_tree(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b324e45",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad9f7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Random Forest function\n",
    "\n",
    "def random_forest(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = rf.predict(x_train) \n",
    "    pred_test = rf.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  rf.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d00ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call random forest function\n",
    "random_forest(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9611d530",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903f282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Support Vector Machine function\n",
    "\n",
    "def support_vector_machine(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.25, random_state=40, stratify = y) \n",
    "    svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train, y_train) \n",
    "    svm_predictions = svm_model_linear.predict(x_test)\n",
    "\n",
    "    pred_train = svm_model_linear.predict(x_train) \n",
    "    pred_test = svm_model_linear.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  svm_model_linear.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9e089f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call support vector machine function\n",
    "\n",
    "support_vector_machine(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e6a1cb",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718841be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "578aae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up xgBoost matrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e28a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e4c0c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 50  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d74ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing - numpy matrices\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362343ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model metrics \n",
    "print(accuracy_score(y_test, best_preds))\n",
    "print(recall_score(y_test, best_preds, average='macro'))\n",
    "print(f1_score(y_test, best_preds, average='macro'))\n",
    "print(precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb5f55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up confusion matrix\n",
    "score = round(accuracy_score(y_test, best_preds), 3)\n",
    "cm1 = confusion_matrix(y_test, best_preds)\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test,best_preds) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31795e4",
   "metadata": {},
   "source": [
    "# Determine Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d56f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X_encoded, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653daa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caf4126b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve column names\n",
    "X_encoded= pd.DataFrame(X_encoded) \n",
    "x_names= X_encoded.iloc[:,:16]\n",
    "x_names=pd.DataFrame(x_names)\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(x_names,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a410632",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_names.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611cd575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(16).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e41fb0",
   "metadata": {},
   "source": [
    "The module type, the year of presentation, the unreg_month, gender and fail rate are the five most important features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4bbd69",
   "metadata": {},
   "source": [
    "# Comparison of Model Performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1902bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Bar Chart for Accuracy of different classifiers\n",
    "sns.set_style(\"white\")\n",
    "plt.figure(figsize=(12, 3))\n",
    "model_accuracies = [0.81, 0.76, 0.73, 0.72, 0.70, 0.69]\n",
    "model_names = ['RandomForest','XGBoost','Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'ANN - MLP']\n",
    "g= sns.barplot(x=model_names, y=model_accuracies, color='grey');\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('seagreen')  \n",
    "g.set_title('Model Accuracy for Dropout', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a99380",
   "metadata": {},
   "source": [
    "# Attempt to Improve the Model Using PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e29103b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the explained variance\n",
    "\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6e6274",
   "metadata": {},
   "source": [
    "Approximately 15 principal components explain 95% of the variance in the data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ccca4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with the first 15 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d42cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier() \n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print('Decision Tree accuracy score with the first 15 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a99ee09",
   "metadata": {},
   "source": [
    "PCA reduces the accuracy of the models so it will be abandoned. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b24394",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
