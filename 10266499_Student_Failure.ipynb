{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa32c97",
   "metadata": {},
   "source": [
    "<img src=\"https://www.dbs.ie/images/default-source/logos/dbs-logo-2019-small.png\" align = left/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7351f5f3",
   "metadata": {},
   "source": [
    "#  Open University Learning Analytics - Student Failure\n",
    "\n",
    "Capstone Project\n",
    "\n",
    "Claire Connaughton (10266499)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc1d627",
   "metadata": {},
   "source": [
    "# Import Relevant Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62a83f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pydotplus\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "from plotnine import *\n",
    "import plotnine\n",
    "plotnine.options.figure_size = (5.2,3.2)\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"white\")\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from scipy import interp\n",
    "from scipy.stats import skew, norm, probplot, boxcox, f_oneway\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "from six import StringIO\n",
    "from collections import Counter\n",
    "from pandas_profiling import ProfileReport\n",
    "from patsy import dmatrices\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, MinMaxScaler, RobustScaler\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.utils import resample \n",
    "from imblearn.over_sampling import SMOTE \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score, KFold, cross_val_predict, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, auc, accuracy_score, mean_absolute_error\n",
    "from sklearn import metrics, tree\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC \n",
    "import xgboost as xgb\n",
    "from sklearn.datasets import dump_svmlight_file\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69573118",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%HTML\n",
    "<style type=\"text/css\">\n",
    "table.dataframe td, table.dataframe th {\n",
    "    border: 1px  black solid !important;\n",
    "  color: black !important;\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f529a",
   "metadata": {},
   "source": [
    "# Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d37641",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned OULA dataset\n",
    "\n",
    "try:\n",
    "    data = pd.read_csv('oulad_cleaned.csv')\n",
    "    print(\"The 'Cleaned OULA' dataset has {} samples with {} features each.\".format(*data.shape))\n",
    "except:\n",
    "    print(\"Dataset could not be loaded. Is the dataset missing?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d9faf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['student_failed'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9424bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of students who passed or failed their course. \n",
    "\n",
    "g = sns.countplot(x ='student_failed', \n",
    "              data = data,\n",
    "              palette='tab20',\n",
    "              order = data['student_failed'].value_counts().index);\n",
    "\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.set_title('Student Outcome', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c366ae",
   "metadata": {},
   "source": [
    "# Bivariate Analysis for Student Failure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4f405",
   "metadata": {},
   "source": [
    "***************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb15d639",
   "metadata": {},
   "source": [
    "# Demographic Details of Students who Failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04499efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "g= sns.catplot('student_failed', col='code_module', col_wrap=4,\n",
    "                data=data[data.code_module.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Number of Fails per Module Type', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d291ea6a",
   "metadata": {},
   "source": [
    "More students failed STEM courses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08534f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a gender difference in fails\n",
    "\n",
    "g= sns.catplot('student_failed', col='gender', col_wrap=4,\n",
    "                data=data[data.gender.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.6) \n",
    "g.fig.suptitle('Number of Fails per Gender', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17397402",
   "metadata": {},
   "source": [
    "Slightly more males failed their course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fb22fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the number of fails per region\n",
    "\n",
    "g= sns.catplot('student_failed', col='region', col_wrap=4,\n",
    "                data=data[data.region.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.8) \n",
    "g.fig.suptitle('Number of Fails per Region', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257b8105",
   "metadata": {},
   "source": [
    "West UK had slightly more fails than any other region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a83d7c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is difference in highest education level among fails\n",
    "\n",
    "g= sns.catplot('student_failed', col='highest_education', col_wrap=1,\n",
    "                data=data[data.highest_education.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.8) \n",
    "g.fig.suptitle('Number of Fails per Education Level', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7178768d",
   "metadata": {},
   "source": [
    "Students with a higher education qualification were the least likely to fail and students with the lowest educational attainment are the most likely to fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f8a6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is difference in socio-economic status among fails\n",
    "\n",
    "g= sns.catplot('student_failed', col='imd_band', col_wrap=4,\n",
    "                data=data[data.imd_band.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.8) \n",
    "g.fig.suptitle('Number of Fails per Socio-Economic Class', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0adaba42",
   "metadata": {},
   "source": [
    "While middle class students were more likely to fail, the socioeconomically disadvantaged students had the second highest failure rate. The privileged group had the lowest failure rates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35ba86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is an age difference among fails\n",
    "\n",
    "g= sns.catplot('student_failed', col='age_band', col_wrap=2,\n",
    "                data=data[data.age_band.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.8) \n",
    "g.fig.suptitle('Number of Fails per Age Group', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe36fe9",
   "metadata": {},
   "source": [
    "Under 35s are the most likely to fail their course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f674b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there is a difference among student ability groups and fails\n",
    "\n",
    "g= sns.catplot('student_failed', col='disability', col_wrap=2,\n",
    "                data=data[data.disability.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.8) \n",
    "g.fig.suptitle('Number of Fails per Disability', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d3b0c8",
   "metadata": {},
   "source": [
    "Disability does not seem to effect failure rate too much."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820fe141",
   "metadata": {},
   "source": [
    "# The demographic profile of students who are more likely to fail is as follows:\n",
    "\n",
    "1) Under 35s\n",
    "\n",
    "\n",
    "2) Male\n",
    "\n",
    "\n",
    "3) Having a disability\n",
    "\n",
    "\n",
    "4) Studying a STEM course\n",
    "\n",
    "\n",
    "5) From a lower socio-economic class\n",
    "\n",
    "\n",
    "6) Holding lower than A-Level education\n",
    "\n",
    "\n",
    "\n",
    "7) From West UK "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff877734",
   "metadata": {},
   "source": [
    "# Behavioural Details of Students who Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad14905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between fails and the number of previous attempts\n",
    "\n",
    "g = sns.catplot(x=\"student_failed\", y=\"num_of_prev_attempts\", palette= \"tab20\", kind=\"bar\", data=data)\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Impact of Previous Attempts on Failure Rates', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e12832",
   "metadata": {},
   "source": [
    "There does not appear to be a strong link between failure and repeating a course. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae85bb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between failure and the number of studied credits\n",
    "\n",
    "g = sns.catplot(x=\"student_failed\", y=\"studied_credits\", palette= \"tab20\", kind=\"bar\", data=data)\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Impact of Studied Credits on Failure Rates', fontsize = 16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45564f1d",
   "metadata": {},
   "source": [
    "The students who failed studied fewer credits. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f17e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between failure and the Average number of clicks\n",
    "\n",
    "g = sns.catplot(x=\"student_failed\", y=\"AVG_click\", palette= \"tab20\", kind= 'bar', data=data)\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Impact of AVG Clicks on Failure', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "025cad38",
   "metadata": {},
   "source": [
    "Students who failed had a lower number of average clicks on the Virtual Learning Environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a9ab40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between dropping out and the total clicks in the VLE\n",
    "\n",
    "g = sns.catplot(x=\"student_failed\", y=\"total_click\", palette= \"tab20\", kind= 'bar', data=data)\n",
    "g.set_xticklabels(['Passed', 'Failed'])\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Impact of Total Clicks on Failure', fontsize = 18)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24bfea89",
   "metadata": {},
   "source": [
    "The students who failed had considerably fewer total clicks than the students who completed the course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebde50e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between fails and late submission of assignments\n",
    "\n",
    "sns.set_theme(style=\"ticks\")\n",
    "g = sns.catplot(x=\"student_failed\", y=\"late_rate\", palette= \"tab20\", kind= 'bar', data=data)\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.9) \n",
    "g.fig.suptitle('Impact of Late Submission on Failure', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c83fdc",
   "metadata": {},
   "source": [
    "Students who failed were more likely to submit their assignment late."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9444f96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Investigate the relationship between failure and the date unregistered\n",
    "\n",
    "g= sns.catplot('student_failed', col='unreg_month', col_wrap=4,\n",
    "                data=data[data.unreg_month.notnull()],\n",
    "                kind=\"count\", height=3.5, aspect=.8, \n",
    "                palette= \"tab20\")\n",
    "g.set_xticklabels(['Did not Fail','Failed'])\n",
    "g.fig.subplots_adjust(top=0.8) \n",
    "g.fig.suptitle('Impact of Date Unregistered on Failure', fontsize = 18)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b51189bb",
   "metadata": {},
   "source": [
    "Every student who dropped out before the end of the course in June, failed. Some students still failed in June. This means that if you completed the course you are more likely to pass. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7a0b3d",
   "metadata": {},
   "source": [
    "# The behaviour profile of students who failed is as follows:\n",
    "\n",
    "1) Studied more credits so their workload was higher\n",
    "\n",
    "2) Less inclined to interact with the VLE\n",
    "\n",
    "\n",
    "3) More likely to submit assignments late\n",
    "\n",
    "\n",
    "4) Completed the course.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf057a3",
   "metadata": {},
   "source": [
    "**********************************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8375afe6",
   "metadata": {},
   "source": [
    "# Multivariate Analysis for Student Failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331285f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use NumPy's corrcoef and seaborn's heatmap functions to plot the correlation matrix array as a heat map.\n",
    "\n",
    "corr= data.corr()\n",
    "top_corr_cols = corr.student_failed.sort_values(ascending=False).keys() \n",
    "top_corr = corr.loc[top_corr_cols, top_corr_cols]\n",
    "dropSelf = np.zeros_like(top_corr)\n",
    "dropSelf[np.triu_indices_from(dropSelf)] = True\n",
    "plt.figure(figsize=(18, 10))\n",
    "sns.heatmap(top_corr, cmap=sns.diverging_palette(220, 10, as_cmap=True), annot=True, fmt=\".2f\", mask=dropSelf)\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "sns.set(font_scale=1.0)\n",
    "cols = data.columns\n",
    "g = sns.pairplot(data = data.loc[:, cols], hue='student_failed')\n",
    "fig = g.fig \n",
    "fig.subplots_adjust(top=0.93, wspace=0.3)\n",
    "t = fig.suptitle('Pairwise Plots by Student Failure', fontsize=24)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "del corr, dropSelf, top_corr, g, fig, t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b5376b",
   "metadata": {},
   "source": [
    "The multivariate analysis provides further confirmation that the students who failed were academically struggling and had lower engagement with the VLE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3938d9cf",
   "metadata": {},
   "source": [
    "# MODEL PREPARATION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaff60b",
   "metadata": {},
   "source": [
    "Checking the Variance Inflation Factor for Each Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e615e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find design matrix for linear regression model using 'rating' as response variable \n",
    "y, X = dmatrices('student_failed ~ code_module+code_presentation+reg_month+unreg_month+gender+region+highest_education+imd_band+age_band+num_of_prev_attempts+disability+studied_credits+total_click+weighted_score+late_rate+fail_rate+procrastination', data=data, return_type='dataframe')\n",
    "\n",
    "#calculate VIF for each explanatory variable\n",
    "vif = pd.DataFrame()\n",
    "vif['VIF'] = [variance_inflation_factor(X.values, i) for i in range(X.shape[1])]\n",
    "vif['variable'] = X.columns\n",
    "\n",
    "#view VIF for each explanatory variable \n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "405981fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using 5 as the minimum vif values i.e any independent variable 5 and above will have to be dropped\n",
    "# From the results all independent variable are below 5\n",
    "# Drop reg_month, unreg_month and code_module columns\n",
    "\n",
    "data.drop(columns=['reg_month', 'unreg_month', 'code_module'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadf7e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the ID column because it's unnecessary for model learning predictions\n",
    "\n",
    "data.drop('id_student', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65685fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Declaring independent variable i.e X\n",
    "#Declaring Target variable i.e y\n",
    "\n",
    "x = data.drop(['student_failed', 'dropout'], axis = 1)\n",
    "y = data['student_failed']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1dab1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set encoding and scaling instructions\n",
    "column_transform = make_column_transformer(\n",
    "    (OneHotEncoder(), ['code_presentation', 'gender', 'region', 'age_band', 'disability']),\n",
    "    (OrdinalEncoder(), ['highest_education', 'imd_band']),\n",
    "    (RobustScaler(), ['num_of_prev_attempts', 'studied_credits', 'total_click', 'late_rate'])\n",
    ")\n",
    "\n",
    "# Apply column transformer to features\n",
    "X_encoded = column_transform.fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466b360",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting data into train and test dataset\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X_encoded, y , test_size = 0.2, random_state  = 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003d8449",
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=40) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01b86b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up SMOTE to treat imbalance in the target variable \n",
    "smote = SMOTE()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sm, y_sm =smote.fit_resample(x_train, y_train) \n",
    "\n",
    "print(x_train.shape, y_train.shape) \n",
    "print(x_sm.shape, y_sm.shape) \n",
    "sns.countplot(y_sm) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293f6784",
   "metadata": {},
   "source": [
    "*******************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46962875",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71e3e60",
   "metadata": {},
   "source": [
    "***********************************"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ca1546",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f2896",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define logistic regression model function\n",
    "def logistic_regression(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    logreg_model = LogisticRegression() \n",
    "    logreg_model.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = logreg_model.predict(x_train) \n",
    "    pred_test = logreg_model.predict(x_test) \n",
    "    cm_train = confusion_matrix(y_train, pred_train) \n",
    "    cm_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  logreg_model.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5923374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call logistic regression model\n",
    "\n",
    "logistic_regression(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d93a8",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define decision tree model function\n",
    "\n",
    "def decision_tree(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    dt = DecisionTreeClassifier() \n",
    "    dt.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = dt.predict(x_train) \n",
    "    pred_test = dt.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  dt.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92a0a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call deicsion tree model\n",
    "\n",
    "decision_tree(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8ead12",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8fe7352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define random forest model function\n",
    "\n",
    "def random_forest(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.20, random_state=40, stratify = y) \n",
    "    rf = RandomForestClassifier() \n",
    "    rf.fit(x_train, y_train) \n",
    "\n",
    "    pred_train = rf.predict(x_train) \n",
    "    pred_test = rf.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  rf.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c8ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call random forest model\n",
    "\n",
    "random_forest(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a36d66",
   "metadata": {},
   "source": [
    "# Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e904f838",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Support Vector Machine model function\n",
    "\n",
    "def support_vector_machine(x, y): \n",
    "    x_train, x_test, y_train, y_test =  train_test_split(x, y, test_size=0.25, random_state=40, stratify = y) \n",
    "    svm_model_linear = SVC(kernel = 'linear', C = 1).fit(x_train, y_train) \n",
    "    svm_predictions = svm_model_linear.predict(x_test)\n",
    "\n",
    "    pred_train = svm_model_linear.predict(x_train) \n",
    "    pred_test = svm_model_linear.predict(x_test) \n",
    "    confusion_matrix_train = confusion_matrix(y_train, pred_train) \n",
    "    confusion_matrix_test = confusion_matrix(y_test, pred_test)\n",
    "    score = round(accuracy_score(y_test, pred_test), 3)\n",
    "    cm1 = confusion_matrix(y_test, pred_test)\n",
    "    sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "    plt.xlabel('Predicted Values')\n",
    "    plt.ylabel('Actual Values')\n",
    "    plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "    plt.show()\n",
    "    print(\"Accuracy of Test Model : \",  svm_model_linear.score(x_test, y_test)) \n",
    "    print(\"Mean Absolute Error : \", mean_absolute_error(pred_test, y_test))\n",
    "    print(\"Train Data Set\") \n",
    "    print(metrics.classification_report(y_train,pred_train) ) \n",
    "    print(\"Test Data Set \") \n",
    "    print(metrics.classification_report(y_test,pred_test) ) \n",
    "    return  None "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d495356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Support Vector Machine model\n",
    "support_vector_machine(x_sm, y_sm) \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acaccb25",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43d9d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922233fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up xgBoost matrix\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b838012e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_svmlight_file(X_train, y_train, 'dtrain.svm', zero_based=True)\n",
    "dump_svmlight_file(X_test, y_test, 'dtest.svm', zero_based=True)\n",
    "dtrain_svm = xgb.DMatrix('dtrain.svm')\n",
    "dtest_svm = xgb.DMatrix('dtest.svm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2bf05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "param = {\n",
    "    'max_depth': 3,  # the maximum depth of each tree\n",
    "    'eta': 0.3,  # the training step for each iteration\n",
    "    'silent': 1,  # logging mode - quiet\n",
    "    'objective': 'multi:softprob',  # error evaluation for multiclass training\n",
    "    'num_class': 3}  # the number of classes that exist in this datset\n",
    "num_round = 50  # the number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and testing - numpy matrices\n",
    "bst = xgb.train(param, dtrain, num_round)\n",
    "preds = bst.predict(dtest)\n",
    "# extracting most confident predictions\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "print (\"Numpy array precision:\", precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a5f9c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print model metrics \n",
    "print(accuracy_score(y_test, best_preds))\n",
    "print(recall_score(y_test, best_preds, average='macro'))\n",
    "print(f1_score(y_test, best_preds, average='macro'))\n",
    "print(precision_score(y_test, best_preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47b240e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up confusion matrix\n",
    "score = round(accuracy_score(y_test, best_preds), 3)\n",
    "cm1 = confusion_matrix(y_test, best_preds)\n",
    "sns.heatmap(cm1, annot=True, fmt=\".0f\")\n",
    "plt.xlabel('Predicted Values')\n",
    "plt.ylabel('Actual Values')\n",
    "plt.title('Accuracy Score: {0}'.format(score), size = 15)\n",
    "plt.show()\n",
    "print(metrics.classification_report(y_test,best_preds) )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de667d8",
   "metadata": {},
   "source": [
    "# Comparing Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad420dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Bar Chart for Accuracy of different classifiers\n",
    "\n",
    "plt.figure(figsize=(12, 3))\n",
    "model_accuracies = [0.83, 0.79, 0.74, 0.64, 0.64]\n",
    "model_names = ['RandomForest','XGBoost','Decision Tree', 'Logistic Regression','Support Vector Machine']\n",
    "g= sns.barplot(x=model_names, y=model_accuracies, color='grey');\n",
    "\n",
    "patch_h = []    \n",
    "for patch in g.patches:\n",
    "    reading = patch.get_height()\n",
    "    patch_h.append(reading)\n",
    "\n",
    "idx_tallest = np.argmax(patch_h)   \n",
    "\n",
    "g.patches[idx_tallest].set_facecolor('seagreen')  \n",
    "g.set_title('Model Accuracy for Student Failure', fontsize = 18)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9bf82f",
   "metadata": {},
   "source": [
    "# Determine Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa8f788",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract feature importance\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(X_encoded, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3e0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve column names\n",
    "X_encoded= pd.DataFrame(X_encoded) \n",
    "x_names= X_encoded.iloc[:,:17]\n",
    "x_names=pd.DataFrame(x_names)\n",
    "model = ExtraTreesRegressor()\n",
    "model.fit(x_names,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460b24c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot graph of feature importances for better visualization\n",
    "feat_importances = pd.Series(model.feature_importances_, index=x.columns)\n",
    "feat_importances.nlargest(8).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd8a4f7",
   "metadata": {},
   "source": [
    "Whether a student procrastinates, fails certain assessments, has late submissions and lower education increases the liklihood that they will fail their course. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceaa858c",
   "metadata": {},
   "source": [
    "# Attempt to improve model accuracy with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73572330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up PCA\n",
    "pca = PCA()\n",
    "X_train = pca.fit_transform(X_train)\n",
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b8fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the optimal number of principal components\n",
    "pca = sklearnPCA().fit(x_sm)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb50433",
   "metadata": {},
   "source": [
    "About 13 components explain 95% of the variance in student failure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f8a1be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run logistic regression with PCA\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Logistic Regression accuracy score with the first 13 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179bd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier() \n",
    "dt.fit(X_train, y_train)\n",
    "y_pred = dt.predict(X_test)\n",
    "print('Decision Tree accuracy score with the first 15 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfb374a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf=RandomForestClassifier() \n",
    "rf.fit(X_train, y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "print('Random Forest accuracy score with the first 15 features: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538b7501",
   "metadata": {},
   "source": [
    "PCA improves predictive accuracy for logistic regression but not the other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6db90e",
   "metadata": {},
   "source": [
    "# END"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
